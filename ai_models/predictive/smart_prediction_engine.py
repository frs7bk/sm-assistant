#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
Smart Prediction Engine with Advanced Machine Learning
"""

import asyncio
import logging
import numpy as np
import pandas as pd
import pickle
import json
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass, asdict, field
from collections import defaultdict, deque
import warnings
warnings.filterwarnings('ignore')

# Machine Learning
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import LinearRegression, Ridge
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.model_selection import train_test_split, TimeSeriesSplit
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# Deep Learning
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    PYTORCH_AVAILABLE = True
except ImportError:
    PYTORCH_AVAILABLE = False

# Time Series
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.seasonal import seasonal_decompose
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

@dataclass
class PredictionRequest:
    """Ø·Ù„Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤"""
    request_id: str
    user_id: str
    prediction_type: str
    input_data: Dict[str, Any]
    time_horizon: timedelta
    confidence_level: float = 0.95
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class PredictionResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤"""
    prediction_id: str
    request_id: str
    predicted_value: Any
    confidence_score: float
    prediction_interval: Tuple[float, float]
    feature_importance: Dict[str, float]
    model_used: str
    accuracy_metrics: Dict[str, float]
    explanation: str
    recommendations: List[str]
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class PredictionModel:
    """Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤"""
    model_id: str
    model_type: str
    model_object: Any
    performance_metrics: Dict[str, float]
    feature_names: List[str]
    last_trained: datetime
    training_data_size: int
    is_active: bool = True

class LSTMPredictor(nn.Module):
    """Ø´Ø¨ÙƒØ© LSTM Ù„Ù„ØªÙ†Ø¨Ø¤"""

    def __init__(self, input_size: int, hidden_size: int = 64, num_layers: int = 2, output_size: int = 1):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.1)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        out, _ = self.lstm(x, (h0, c0))
        out = self.dropout(out[:, -1, :])
        out = self.fc(out)

        return out

class SmartPredictionEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ
        self.is_initialized = False
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.models: Dict[str, PredictionModel] = {}
        self.model_selector = None

        # Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.scalers: Dict[str, StandardScaler] = {}
        self.encoders: Dict[str, LabelEncoder] = {}

        # ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        self.prediction_history = deque(maxlen=10000)
        self.model_performance_history = defaultdict(list)

        # Ù…Ø®Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.training_data: Dict[str, pd.DataFrame] = {}
        self.feature_store = {}

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.performance_stats = {
            "total_predictions": 0,
            "successful_predictions": 0,
            "average_accuracy": 0.0,
            "models_trained": 0,
            "avg_processing_time": 0.0
        }

        # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø­ÙØ¸
        self.models_dir = Path("data/prediction_models")
        self.models_dir.mkdir(parents=True, exist_ok=True)

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤
        self.prediction_config = {
            "min_training_samples": 50,
            "retrain_threshold": 0.1,  # ØªØ±Ø§Ø¬Ø¹ ÙÙŠ Ø§Ù„Ø¯Ù‚Ø©
            "max_models_per_type": 5,
            "ensemble_threshold": 3,  # Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„ØªØµÙˆÙŠØª
            "confidence_threshold": 0.7
        }

    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤"""
        self.logger.info("ğŸ”® ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")

        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
            await self._load_saved_models()

            # ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            await self._initialize_model_selector()

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
            await self._load_training_data()

            self.is_initialized = True
            self.logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø¬Ø§Ø­")

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            # ØªÙ‡ÙŠØ¦Ø© Ø£Ø³Ø§Ø³ÙŠØ©
            self.is_initialized = True

    async def _load_saved_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            model_files = list(self.models_dir.glob("*.pkl"))

            for model_file in model_files:
                try:
                    with open(model_file, 'rb') as f:
                        model_data = pickle.load(f)

                    self.models[model_data['model_id']] = PredictionModel(**model_data)
                    self.logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_data['model_id']}")

                except Exception as e:
                    self.logger.warning(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_file}: {e}")

            if self.models:
                self.logger.info(f"ğŸ“Š ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.models)} Ù†Ù…ÙˆØ°Ø¬")

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")

    async def _initialize_model_selector(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        try:
            if SKLEARN_AVAILABLE:
                # Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ ØªÙ†Ø¨Ø¤
                self.model_selector = RandomForestRegressor(
                    n_estimators=50,
                    random_state=42
                )

                self.logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")

        except Exception as e:
            self.logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")

    async def _load_training_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©"""
        try:
            data_dir = Path("data/training")
            if data_dir.exists():
                for data_file in data_dir.glob("*.csv"):
                    try:
                        df = pd.read_csv(data_file)
                        dataset_name = data_file.stem
                        self.training_data[dataset_name] = df

                        self.logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª: {dataset_name}")

                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {data_file}: {e}")

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©: {e}")

    async def predict(self, request: PredictionRequest) -> PredictionResult:
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤"""
        start_time = datetime.now()

        try:
            self.performance_stats["total_predictions"] += 1

            # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
            best_model = await self._select_best_model(request)

            if not best_model:
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯
                best_model = await self._create_new_model(request)

            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            processed_data = await self._prepare_prediction_data(request, best_model)

            # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤
            prediction_value = await self._execute_prediction(best_model, processed_data)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„ÙØªØ±Ø©
            confidence, interval = await self._calculate_confidence(
                best_model, processed_data, prediction_value
            )

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙØ³ÙŠØ± ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
            explanation = await self._generate_explanation(best_model, processed_data, prediction_value)
            recommendations = await self._generate_recommendations(request, prediction_value)

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            result = PredictionResult(
                prediction_id=f"pred_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{request.user_id}",
                request_id=request.request_id,
                predicted_value=prediction_value,
                confidence_score=confidence,
                prediction_interval=interval,
                feature_importance=await self._get_feature_importance(best_model),
                model_used=best_model.model_id,
                accuracy_metrics=best_model.performance_metrics,
                explanation=explanation,
                recommendations=recommendations
            )

            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
            self.prediction_history.append(result)

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            processing_time = (datetime.now() - start_time).total_seconds()
            self.performance_stats["successful_predictions"] += 1
            self._update_performance_stats(processing_time)

            self.logger.info(f"âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø¬Ø§Ø­: {result.prediction_id}")

            return result

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")

            # Ù†ØªÙŠØ¬Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            return PredictionResult(
                prediction_id=f"pred_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                request_id=request.request_id,
                predicted_value=None,
                confidence_score=0.0,
                prediction_interval=(0.0, 0.0),
                feature_importance={},
                model_used="error",
                accuracy_metrics={"error": str(e)},
                explanation="Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤",
                recommendations=["ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"]
            )

    async def _select_best_model(self, request: PredictionRequest) -> Optional[PredictionModel]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªÙ†Ø¨Ø¤"""
        try:
            # ØªØµÙÙŠØ© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
            suitable_models = [
                model for model in self.models.values()
                if model.is_active and model.model_type == request.prediction_type
            ]

            if not suitable_models:
                return None

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡
            suitable_models.sort(
                key=lambda m: m.performance_metrics.get('accuracy', 0.0),
                reverse=True
            )

            return suitable_models[0]

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return None

    async def _create_new_model(self, request: PredictionRequest) -> PredictionModel:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯"""
        try:
            model_id = f"{request.prediction_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if request.prediction_type == "time_series":
                model_object = await self._create_time_series_model()
            elif request.prediction_type == "regression":
                model_object = await self._create_regression_model()
            elif request.prediction_type == "classification":
                model_object = await self._create_classification_model()
            else:
                model_object = await self._create_general_model()

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤
            prediction_model = PredictionModel(
                model_id=model_id,
                model_type=request.prediction_type,
                model_object=model_object,
                performance_metrics={},
                feature_names=[],
                last_trained=datetime.now(),
                training_data_size=0
            )

            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø¨ÙŠØ§Ù†Ø§Øª
            await self._train_model(prediction_model, request)

            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            self.models[model_id] = prediction_model
            await self._save_model(prediction_model)

            self.performance_stats["models_trained"] += 1

            return prediction_model

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {e}")
            raise

    async def _create_time_series_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        if PYTORCH_AVAILABLE:
            return LSTMPredictor(input_size=10, hidden_size=64, num_layers=2)
        elif SKLEARN_AVAILABLE:
            return RandomForestRegressor(n_estimators=100, random_state=42)
        else:
            return None

    async def _create_regression_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±"""
        if SKLEARN_AVAILABLE:
            return GradientBoostingRegressor(n_estimators=100, random_state=42)
        else:
            return None

    async def _create_classification_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ"""
        if SKLEARN_AVAILABLE:
            from sklearn.ensemble import RandomForestClassifier
            return RandomForestClassifier(n_estimators=100, random_state=42)
        else:
            return None

    async def _create_general_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù…"""
        if SKLEARN_AVAILABLE:
            return RandomForestRegressor(n_estimators=50, random_state=42)
        else:
            return None

    async def _train_model(self, model: PredictionModel, request: PredictionRequest):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø©
            training_data = await self._get_training_data(request.prediction_type)

            if training_data is None or len(training_data) < self.prediction_config["min_training_samples"]:
                self.logger.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙƒØ§ÙÙŠØ©")
                return

            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X, y = await self._prepare_training_data(training_data, request)

            if X is None or y is None:
                return

            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )

            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            if PYTORCH_AVAILABLE and isinstance(model.model_object, nn.Module):
                await self._train_neural_model(model, X_train, y_train, X_test, y_test)
            elif SKLEARN_AVAILABLE:
                await self._train_sklearn_model(model, X_train, y_train, X_test, y_test)

            # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.feature_names = list(X.columns) if isinstance(X, pd.DataFrame) else [f"feature_{i}" for i in range(X.shape[1])]
            model.training_data_size = len(training_data)
            model.last_trained = datetime.now()

            self.logger.info(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model.model_id}")

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")

    async def _train_neural_model(self, model: PredictionModel, X_train, y_train, X_test, y_test):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ"""
        try:
            model.model_object.to(self.device)

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train_tensor = torch.FloatTensor(X_train.values if isinstance(X_train, pd.DataFrame) else X_train)
            y_train_tensor = torch.FloatTensor(y_train.values if isinstance(y_train, pd.Series) else y_train)
            X_test_tensor = torch.FloatTensor(X_test.values if isinstance(X_test, pd.DataFrame) else X_test)
            y_test_tensor = torch.FloatTensor(y_test.values if isinstance(y_test, pd.Series) else y_test)

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            optimizer = optim.Adam(model.model_object.parameters(), lr=0.001)
            criterion = nn.MSELoss()

            # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            model.model_object.train()
            for epoch in range(100):
                optimizer.zero_grad()
                outputs = model.model_object(X_train_tensor.unsqueeze(1))
                loss = criterion(outputs.squeeze(), y_train_tensor)
                loss.backward()
                optimizer.step()

            # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            model.model_object.eval()
            with torch.no_grad():
                test_outputs = model.model_object(X_test_tensor.unsqueeze(1))
                test_predictions = test_outputs.squeeze().cpu().numpy()

                mse = mean_squared_error(y_test, test_predictions)
                r2 = r2_score(y_test, test_predictions)

                model.performance_metrics = {
                    "mse": float(mse),
                    "r2": float(r2),
                    "accuracy": float(max(0, r2))  # Ø§Ø³ØªØ®Ø¯Ø§Ù… RÂ² ÙƒÙ…Ù‚ÙŠØ§Ø³ Ø¯Ù‚Ø©
                }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ: {e}")

    async def _train_sklearn_model(self, model: PredictionModel, X_train, y_train, X_test, y_test):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ sklearn"""
        try:
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.model_object.fit(X_train, y_train)

            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            y_pred = model.model_object.predict(X_test)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

            model.performance_metrics = {
                "mse": float(mse),
                "mae": float(mae),
                "r2": float(r2),
                "accuracy": float(max(0, r2))
            }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ sklearn: {e}")

    async def _get_training_data(self, prediction_type: str) -> Optional[pd.DataFrame]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
            for dataset_name, data in self.training_data.items():
                if prediction_type in dataset_name.lower():
                    return data

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯
            return await self._generate_synthetic_data(prediction_type)

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
            return None

    async def _generate_synthetic_data(self, prediction_type: str) -> pd.DataFrame:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
        try:
            np.random.seed(42)
            n_samples = 1000

            if prediction_type == "time_series":
                # Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ù„Ø³Ù„Ø© Ø²Ù…Ù†ÙŠØ©
                dates = pd.date_range(start='2023-01-01', periods=n_samples, freq='D')
                trend = np.linspace(100, 200, n_samples)
                seasonal = 10 * np.sin(2 * np.pi * np.arange(n_samples) / 365.25)
                noise = np.random.normal(0, 5, n_samples)
                values = trend + seasonal + noise

                return pd.DataFrame({
                    'date': dates,
                    'value': values,
                    'target': values + np.random.normal(0, 2, n_samples)
                })

            else:
                # Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø§Ù…Ø©
                data = {
                    'feature_1': np.random.normal(0, 1, n_samples),
                    'feature_2': np.random.normal(5, 2, n_samples),
                    'feature_3': np.random.uniform(0, 10, n_samples),
                    'feature_4': np.random.exponential(2, n_samples)
                }

                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹
                df = pd.DataFrame(data)
                df['target'] = (
                    2 * df['feature_1'] + 
                    0.5 * df['feature_2'] - 
                    0.3 * df['feature_3'] + 
                    0.1 * df['feature_4'] + 
                    np.random.normal(0, 0.5, n_samples)
                )

                return df

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {e}")
            return pd.DataFrame()

    async def _prepare_training_data(self, data: pd.DataFrame, request: PredictionRequest) -> Tuple[Optional[pd.DataFrame], Optional[pd.Series]]:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            if data.empty:
                return None, None

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹
            target_column = 'target'
            if target_column not in data.columns:
                # Ø§Ø®ØªÙŠØ§Ø± Ø¢Ø®Ø± Ø¹Ù…ÙˆØ¯ ÙƒÙ…ØªØºÙŠØ± ØªØ§Ø¨Ø¹
                target_column = data.columns[-1]

            # ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹
            X = data.drop(columns=[target_column])
            y = data[target_column]

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
            X = X.fillna(X.mean() if X.select_dtypes(include=[np.number]).shape[1] > 0 else X.mode().iloc[0])
            y = y.fillna(y.mean())

            # ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ©
            for column in X.select_dtypes(include=['object']).columns:
                if column not in self.encoders:
                    self.encoders[column] = LabelEncoder()

                X[column] = self.encoders[column].fit_transform(X[column].astype(str))

            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            scaler_key = f"{request.prediction_type}_scaler"
            if scaler_key not in self.scalers:
                self.scalers[scaler_key] = StandardScaler()

            X_scaled = pd.DataFrame(
                self.scalers[scaler_key].fit_transform(X),
                columns=X.columns,
                index=X.index
            )

            return X_scaled, y

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
            return None, None

    async def _prepare_prediction_data(self, request: PredictionRequest, model: PredictionModel) -> Optional[np.ndarray]:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¥Ù„Ù‰ DataFrame
            input_df = pd.DataFrame([request.input_data])

            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            for feature in model.feature_names:
                if feature not in input_df.columns:
                    input_df[feature] = 0  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            input_df = input_df[model.feature_names]

            # ØªØ·Ø¨ÙŠÙ‚ Ù†ÙØ³ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            scaler_key = f"{request.prediction_type}_scaler"
            if scaler_key in self.scalers:
                input_scaled = self.scalers[scaler_key].transform(input_df)
                return input_scaled

            return input_df.values

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return None

    async def _execute_prediction(self, model: PredictionModel, data: np.ndarray) -> Any:
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤"""
        try:
            if PYTORCH_AVAILABLE and isinstance(model.model_object, nn.Module):
                # ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ
                model.model_object.eval()
                with torch.no_grad():
                    input_tensor = torch.FloatTensor(data)
                    output = model.model_object(input_tensor.unsqueeze(1))
                    return float(output.squeeze().cpu().numpy())

            elif SKLEARN_AVAILABLE and hasattr(model.model_object, 'predict'):
                # ØªÙ†Ø¨Ø¤ Ù†Ù…ÙˆØ°Ø¬ sklearn
                prediction = model.model_object.predict(data)
                return float(prediction[0]) if isinstance(prediction, np.ndarray) else float(prediction)

            else:
                # Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                return float(np.mean(data))

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return 0.0

    async def _calculate_confidence(self, model: PredictionModel, data: np.ndarray, prediction: Any) -> Tuple[float, Tuple[float, float]]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© ÙˆÙØªØ±Ø© Ø§Ù„ØªÙ†Ø¨Ø¤"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            base_confidence = model.performance_metrics.get('accuracy', 0.5)

            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data_quality = 1.0 - (np.std(data) / (np.mean(np.abs(data)) + 1e-8))
            data_quality = max(0.0, min(1.0, data_quality))

            confidence = (base_confidence + data_quality) / 2

            # Ø­Ø³Ø§Ø¨ ÙØªØ±Ø© Ø§Ù„Ø«Ù‚Ø©
            error_margin = model.performance_metrics.get('mse', 1.0) ** 0.5
            interval = (
                float(prediction - 1.96 * error_margin),
                float(prediction + 1.96 * error_margin)
            )

            return float(confidence), interval

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©: {e}")
            return 0.5, (0.0, 0.0)

    async def _get_feature_importance(self, model: PredictionModel) -> Dict[str, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
        try:
            importance = {}

            if hasattr(model.model_object, 'feature_importances_'):
                # Ù†Ù…Ø§Ø°Ø¬ sklearn Ù…Ø¹ feature_importances_
                importances = model.model_object.feature_importances_
                for i, importance_value in enumerate(importances):
                    feature_name = model.feature_names[i] if i < len(model.feature_names) else f"feature_{i}"
                    importance[feature_name] = float(importance_value)

            elif hasattr(model.model_object, 'coef_'):
                # Ù†Ù…Ø§Ø°Ø¬ Ø®Ø·ÙŠØ©
                coefficients = model.model_object.coef_
                for i, coef in enumerate(coefficients):
                    feature_name = model.feature_names[i] if i < len(model.feature_names) else f"feature_{i}"
                    importance[feature_name] = float(abs(coef))

            else:
                # Ø£Ù‡Ù…ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…ØªØ³Ø§ÙˆÙŠØ©
                for feature_name in model.feature_names:
                    importance[feature_name] = 1.0 / len(model.feature_names)

            return importance

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª: {e}")
            return {}

    async def _generate_explanation(self, model: PredictionModel, data: np.ndarray, prediction: Any) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙØ³ÙŠØ± Ù„Ù„ØªÙ†Ø¨Ø¤"""
        try:
            feature_importance = await self._get_feature_importance(model)

            if not feature_importance:
                return f"Ø§Ù„ØªÙ†Ø¨Ø¤: {prediction:.2f} Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ {model.model_type}"

            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª
            top_features = sorted(
                feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:3]

            explanation = f"Ø§Ù„ØªÙ†Ø¨Ø¤: {prediction:.2f}\n"
            explanation += f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {model.model_type}\n"
            explanation += f"Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model.performance_metrics.get('accuracy', 0):.1%}\n"
            explanation += "Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø©:\n"

            for feature, importance in top_features:
                explanation += f"â€¢ {feature}: {importance:.1%}\n"

            return explanation

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙØ³ÙŠØ±: {e}")
            return f"Ø§Ù„ØªÙ†Ø¨Ø¤: {prediction}"

    async def _generate_recommendations(self, request: PredictionRequest, prediction: Any) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        try:
            recommendations = []

            if request.prediction_type == "time_series":
                if isinstance(prediction, (int, float)):
                    if prediction > 0:
                        recommendations.append("Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… Ø¥ÙŠØ¬Ø§Ø¨ÙŠ")
                        recommendations.append("Ø§Ø³ØªØ¹Ø¯ Ù„Ù„Ù†Ù…Ùˆ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹")
                    else:
                        recommendations.append("Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… Ø³Ù„Ø¨ÙŠ")
                        recommendations.append("Ø§ØªØ®Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙˆÙ‚Ø§Ø¦ÙŠØ©")

            elif request.prediction_type == "regression":
                recommendations.append("Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©")
                recommendations.append("Ø­Ø¯Ø« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù†ØªØ¸Ø§Ù…")

            # ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù…Ø©
            recommendations.extend([
                "Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙƒØ¯Ù„ÙŠÙ„ ÙˆÙ„ÙŠØ³ Ù‚Ø±Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠ",
                "Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡Ø§",
                "Ù‚Ø§Ø±Ù† Ù…Ø¹ ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰"
            ])

            return recommendations[:5]  # Ø£Ù‚ØµÙ‰ 5 ØªÙˆØµÙŠØ§Øª

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {e}")
            return ["Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø°Ø±"]

    async def _save_model(self, model: PredictionModel):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            model_data = {
                'model_id': model.model_id,
                'model_type': model.model_type,
                'model_object': model.model_object,
                'performance_metrics': model.performance_metrics,
                'feature_names': model.feature_names,
                'last_trained': model.last_trained,
                'training_data_size': model.training_data_size,
                'is_active': model.is_active
            }

            model_file = self.models_dir / f"{model.model_id}.pkl"
            with open(model_file, 'wb') as f:
                pickle.dump(model_data, f)

            self.logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model.model_id}")

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")

    def _update_performance_stats(self, processing_time: float):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            total = self.performance_stats["total_predictions"]
            current_avg = self.performance_stats["avg_processing_time"]

            new_avg = (current_avg * (total - 1) + processing_time) / total
            self.performance_stats["avg_processing_time"] = new_avg

            # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©
            if self.models:
                total_accuracy = sum(
                    model.performance_metrics.get('accuracy', 0.0)
                    for model in self.models.values()
                )
                self.performance_stats["average_accuracy"] = total_accuracy / len(self.models)

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")

    async def get_prediction_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¨Ø¤"""
        try:
            stats = {
                "performance": self.performance_stats,
                "models": {
                    "total_models": len(self.models),
                    "active_models": sum(1 for m in self.models.values() if m.is_active),
                    "model_types": list(set(m.model_type for m in self.models.values())),
                    "best_model": max(
                        self.models.values(),
                        key=lambda m: m.performance_metrics.get('accuracy', 0),
                        default=None
                    ).model_id if self.models else None
                },
                "predictions": {
                    "total_predictions": len(self.prediction_history),
                    "recent_predictions": len([
                        p for p in self.prediction_history
                        if (datetime.now() - p.timestamp).days < 7
                    ]),
                    "average_confidence": np.mean([
                        p.confidence_score for p in self.prediction_history
                    ]) if self.prediction_history else 0.0
                },
                "data": {
                    "training_datasets": len(self.training_data),
                    "feature_encoders": len(self.encoders),
                    "data_scalers": len(self.scalers)
                }
            }

            return stats

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
            return {"error": str(e)}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø¹Ø§Ù…
smart_prediction_engine = SmartPredictionEngine()

async def get_smart_prediction_engine() -> SmartPredictionEngine:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠ"""
    if not smart_prediction_engine.is_initialized:
        await smart_prediction_engine.initialize()
    return smart_prediction_engine

if __name__ == "__main__":
    async def test_prediction_engine():
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤"""
        print("ğŸ”® Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
        print("=" * 50)

        engine = await get_smart_prediction_engine()

        # Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ ØªÙ†Ø¨Ø¤ ØªØ¬Ø±ÙŠØ¨ÙŠ
        request = PredictionRequest(
            request_id="test_request_001",
            user_id="test_user",
            prediction_type="regression",
            input_data={
                "feature_1": 1.5,
                "feature_2": 2.3,
                "feature_3": 0.8,
                "feature_4": 1.2
            },
            time_horizon=timedelta(days=7),
            confidence_level=0.95
        )

        print(f"ğŸ“ Ø·Ù„Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤:")
        print(f"  â€¢ Ø§Ù„Ù†ÙˆØ¹: {request.prediction_type}")
        print(f"  â€¢ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {request.input_data}")
        print(f"  â€¢ Ø§Ù„Ø£ÙÙ‚ Ø§Ù„Ø²Ù…Ù†ÙŠ: {request.time_horizon.days} Ø£ÙŠØ§Ù…")

        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤
        result = await engine.predict(request)

        print(f"\nğŸ¯ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤:")
        print(f"  â€¢ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: {result.predicted_value}")
        print(f"  â€¢ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {result.confidence_score:.1%}")
        print(f"  â€¢ ÙØªØ±Ø© Ø§Ù„ØªÙ†Ø¨Ø¤: {result.prediction_interval}")
        print(f"  â€¢ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {result.model_used}")

        if result.feature_importance:
            print(f"\nğŸ” Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª:")
            for feature, importance in result.feature_importance.items():
                print(f"  â€¢ {feature}: {importance:.1%}")

        print(f"\nğŸ“ Ø§Ù„ØªÙØ³ÙŠØ±:")
        print(f"  {result.explanation}")

        if result.recommendations:
            print(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in result.recommendations:
                print(f"  â€¢ {rec}")

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        stats = await engine.get_prediction_statistics()
        print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
        print(f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª: {stats['performance']['total_predictions']}")
        print(f"  â€¢ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {stats['performance']['successful_predictions']}")
        print(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {stats['performance']['average_accuracy']:.1%}")
        print(f"  â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {stats['models']['total_models']}")

        print("\nâœ¨ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    asyncio.run(test_prediction_engine())