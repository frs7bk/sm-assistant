
import torch
import soundfile as sf
from TTS.utils.manage import ModelManager
from TTS.utils.synthesizer import Synthesizer
import librosa
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import json
import os
from datetime import datetime

class UltraNaturalTTS:
    def __init__(self):
        print("[INFO] ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… TTS Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØµÙˆØª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ...")
        
        # Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        self.models = {
            'arabic': {
                'model': "tts_models/ar/cv/vits",
                'quality': 'high'
            },
            'english': {
                'model': "tts_models/en/ljspeech/tacotron2-DDC_ph",
                'quality': 'ultra_high'
            },
            'multilingual': {
                'model': "tts_models/multilingual/multi-dataset/xtts_v2",
                'quality': 'neural'
            }
        }
        
        self.manager = ModelManager()
        self.synthesizers = {}
        self.current_synthesizer = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.voice_settings = {
            'speed_variance': 0.1,      # ØªÙ†ÙˆÙŠØ¹ Ø§Ù„Ø³Ø±Ø¹Ø©
            'pitch_variance': 0.05,     # ØªÙ†ÙˆÙŠØ¹ Ø§Ù„Ù†Ø¨Ø±Ø©  
            'pause_insertion': True,    # Ø¥Ø¯Ø±Ø§Ø¬ ÙˆÙ‚ÙØ§Øª Ø·Ø¨ÙŠØ¹ÙŠØ©
            'breathing_sounds': True,   # Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙ†ÙØ³
            'emotion_modulation': True, # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø·ÙØ©
            'prosody_enhancement': True # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        }
        
        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.emotion_profiles = {
            'neutral': {
                'speed': 1.0, 'pitch': 1.0, 'energy': 1.0,
                'pauses': 'normal', 'breathing': 'subtle'
            },
            'happy': {
                'speed': 1.1, 'pitch': 1.2, 'energy': 1.3,
                'pauses': 'short', 'breathing': 'light'
            },
            'sad': {
                'speed': 0.8, 'pitch': 0.9, 'energy': 0.7,
                'pauses': 'long', 'breathing': 'heavy'
            },
            'excited': {
                'speed': 1.3, 'pitch': 1.4, 'energy': 1.5,
                'pauses': 'minimal', 'breathing': 'quick'
            },
            'calm': {
                'speed': 0.9, 'pitch': 1.0, 'energy': 0.8,
                'pauses': 'extended', 'breathing': 'deep'
            },
            'confident': {
                'speed': 1.0, 'pitch': 1.1, 'energy': 1.2,
                'pauses': 'strategic', 'breathing': 'controlled'
            }
        }
        
        self._load_default_synthesizer()
    
    def _load_default_synthesizer(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ"""
        try:
            model_info = self.models['multilingual']
            model_path, config_path, _ = self.manager.download_model(model_info['model'])
            
            self.current_synthesizer = Synthesizer(
                tts_checkpoint=model_path,
                tts_config_path=config_path,
                use_cuda=torch.cuda.is_available()
            )
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ø±Ùƒ TTS Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ: {e}")
            self._load_fallback_synthesizer()
    
    def _load_fallback_synthesizer(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ø±Ùƒ Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        try:
            model_info = self.models['english']
            model_path, config_path, _ = self.manager.download_model(model_info['model'])
            
            self.current_synthesizer = Synthesizer(
                tts_checkpoint=model_path,
                tts_config_path=config_path
            )
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ Ø­Ø±Ø¬ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ: {e}")
    
    def detect_language(self, text):
        """ÙƒØ´Ù Ù„ØºØ© Ø§Ù„Ù†Øµ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        arabic_chars = sum(1 for char in text if '\u0600' <= char <= '\u06FF')
        total_chars = len([c for c in text if c.isalpha()])
        
        if total_chars == 0:
            return 'english'
        
        arabic_ratio = arabic_chars / total_chars
        
        if arabic_ratio > 0.3:
            return 'arabic'
        else:
            return 'english'
    
    def detect_emotion(self, text):
        """ÙƒØ´Ù Ø§Ù„Ø¹Ø§Ø·ÙØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        text_lower = text.lower()
        
        emotion_keywords = {
            'happy': ['Ø³Ø¹ÙŠØ¯', 'ÙØ±Ø­', 'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'happy', 'great', 'wonderful'],
            'sad': ['Ø­Ø²ÙŠÙ†', 'Ø£Ø³Ù', 'Ù…Ø¤Ø³Ù', 'sad', 'sorry', 'disappointed'],
            'excited': ['Ù…ØªØ­Ù…Ø³', 'Ø±Ø§Ø¦Ø¹', 'Ù…Ø°Ù‡Ù„', 'excited', 'amazing', 'awesome'],
            'calm': ['Ù‡Ø§Ø¯Ø¦', 'Ù…Ø±ÙŠØ­', 'calm', 'peaceful', 'relax'],
            'confident': ['ÙˆØ§Ø«Ù‚', 'Ù…ØªØ£ÙƒØ¯', 'confident', 'sure', 'certain']
        }
        
        for emotion, keywords in emotion_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                return emotion
        
        return 'neutral'
    
    def preprocess_text(self, text, language='auto'):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©"""
        if language == 'auto':
            language = self.detect_language(text)
        
        # Ø¥Ø¶Ø§ÙØ© ÙˆÙ‚ÙØ§Øª Ø·Ø¨ÙŠØ¹ÙŠØ©
        if self.voice_settings['pause_insertion']:
            text = self._insert_natural_pauses(text)
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø·Ù‚
        text = self._enhance_pronunciation(text, language)
        
        return text
    
    def _insert_natural_pauses(self, text):
        """Ø¥Ø¯Ø±Ø§Ø¬ ÙˆÙ‚ÙØ§Øª Ø·Ø¨ÙŠØ¹ÙŠØ©"""
        # ÙˆÙ‚ÙØ§Øª Ù‚ØµÙŠØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„ÙÙˆØ§ØµÙ„
        text = text.replace(',', ', <break time="0.3s"/>')
        text = text.replace('ØŒ', 'ØŒ <break time="0.3s"/>')
        
        # ÙˆÙ‚ÙØ§Øª Ù…ØªÙˆØ³Ø·Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø·
        text = text.replace('.', '. <break time="0.6s"/>')
        text = text.replace('ØŸ', 'ØŸ <break time="0.6s"/>')
        text = text.replace('!', '! <break time="0.6s"/>')
        
        # ÙˆÙ‚ÙØ§Øª Ø·ÙˆÙŠÙ„Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
        text = text.replace('. <break time="0.6s"/>', '. <break time="0.8s"/>')
        
        return text
    
    def _enhance_pronunciation(self, text, language):
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø·Ù‚"""
        if language == 'arabic':
            # ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            pronunciation_map = {
                'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ': 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§Øµ Ø·Ù†Ø§Ø¹ÙŠ',
                'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯': 'Ø§Ù„Ù…ÙØ³Ø§Ø¹Ø¯',
                'Ø§Ù„ØªÙ‚Ù†ÙŠØ©': 'Ø§Ù„ØªÙÙ‚Ù†ÙŠØ©'
            }
        else:
            # ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
            pronunciation_map = {
                'AI': 'A I',
                'API': 'A P I',
                'URL': 'U R L'
            }
        
        for original, improved in pronunciation_map.items():
            text = text.replace(original, improved)
        
        return text
    
    def synthesize_ultra_natural(self, text, emotion='auto', speaker_id=None, 
                                output_path="ultra_natural_output.wav"):
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ø·Ø¨ÙŠØ¹ÙŠ Ù„Ù„ØºØ§ÙŠØ©"""
        
        # ÙƒØ´Ù Ø§Ù„Ø¹Ø§Ø·ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù„Ù… ØªØ­Ø¯Ø¯
        if emotion == 'auto':
            emotion = self.detect_emotion(text)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
        processed_text = self.preprocess_text(text)
        
        print(f"ğŸ™ï¸ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ø·Ø¨ÙŠØ¹ÙŠ: '{text[:50]}...'")
        print(f"ğŸ­ Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {emotion}")
        
        try:
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            if speaker_id:
                wav = self.current_synthesizer.tts(
                    processed_text, 
                    speaker_name=speaker_id
                )
            else:
                wav = self.current_synthesizer.tts(processed_text)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            enhanced_wav = self._apply_advanced_processing(wav, emotion)
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            sf.write(output_path, enhanced_wav, 22050)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            self._post_process_audio(output_path, emotion)
            
            print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
            return None
    
    def _apply_advanced_processing(self, wav, emotion):
        """ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØµÙˆØª"""
        enhanced_wav = np.copy(wav)
        profile = self.emotion_profiles.get(emotion, self.emotion_profiles['neutral'])
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ù†Ø¨Ø±Ø©
        if self.voice_settings['speed_variance']:
            # Ø¥Ø¶Ø§ÙØ© ØªÙ†ÙˆÙŠØ¹ Ø·ÙÙŠÙ ÙÙŠ Ø§Ù„Ø³Ø±Ø¹Ø©
            speed_variation = np.random.normal(1.0, self.voice_settings['speed_variance'])
            speed_factor = profile['speed'] * speed_variation
            enhanced_wav = librosa.effects.time_stretch(enhanced_wav, rate=speed_factor)
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ø¨Ø±Ø©
        if self.voice_settings['pitch_variance']:
            pitch_variation = np.random.normal(1.0, self.voice_settings['pitch_variance'])
            pitch_factor = profile['pitch'] * pitch_variation
            enhanced_wav = librosa.effects.pitch_shift(
                enhanced_wav, sr=22050, n_steps=pitch_factor
            )
        
        # Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙ†ÙØ³ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
        if self.voice_settings['breathing_sounds']:
            enhanced_wav = self._add_breathing_sounds(enhanced_wav, profile)
        
        return enhanced_wav
    
    def _add_breathing_sounds(self, wav, profile):
        """Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª ØªÙ†ÙØ³ Ø·Ø¨ÙŠØ¹ÙŠØ©"""
        # Ø¥Ù†Ø´Ø§Ø¡ Ø£ØµÙˆØ§Øª ØªÙ†ÙØ³ Ø®ÙÙŠÙØ©
        breath_positions = self._find_breath_positions(wav)
        
        for pos in breath_positions:
            if pos < len(wav) - 1000:  # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø§Ø­Ø© ÙƒØ§ÙÙŠØ©
                breath_sound = self._generate_breath_sound(profile['breathing'])
                # Ø¯Ù…Ø¬ ØµÙˆØª Ø§Ù„ØªÙ†ÙØ³
                end_pos = min(pos + len(breath_sound), len(wav))
                wav[pos:end_pos] += breath_sound[:end_pos-pos] * 0.1
        
        return wav
    
    def _find_breath_positions(self, wav):
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ø¶Ø¹ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙ†ÙØ³"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙØªØ±Ø§Øª Ø§Ù„ØµÙ…Øª
        silence_threshold = 0.01
        silence_positions = []
        
        for i in range(0, len(wav) - 1000, 1000):
            segment = wav[i:i+1000]
            if np.max(np.abs(segment)) < silence_threshold:
                silence_positions.append(i)
        
        return silence_positions[::3]  # ÙƒÙ„ Ø«Ø§Ù„Ø« Ù…ÙˆØ¶Ø¹ ØµÙ…Øª
    
    def _generate_breath_sound(self, breath_type):
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª ØªÙ†ÙØ³"""
        duration = 0.2  # 200ms
        samples = int(22050 * duration)
        
        # Ø¶ÙˆØ¶Ø§Ø¡ Ø¨ÙŠØ¶Ø§Ø¡ Ø®ÙÙŠÙØ© ØªØ­Ø§ÙƒÙŠ Ø§Ù„ØªÙ†ÙØ³
        breath = np.random.normal(0, 0.01, samples)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ Ù„ØªÙ‚Ù„ÙŠØ¯ ØµÙˆØª Ø§Ù„ØªÙ†ÙØ³
        breath = librosa.effects.preemphasis(breath)
        
        # ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù…ÙˆØ¬Ø©
        envelope = np.exp(-np.linspace(0, 3, samples))
        breath *= envelope
        
        return breath
    
    def _post_process_audio(self, audio_path, emotion):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆÙ„ÙŠØ¯"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            audio = AudioSegment.from_wav(audio_path)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø¶ØºØ· Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©
            audio = compress_dynamic_range(audio)
            
            # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
            audio = normalize(audio)
            
            # ØªØ­Ø³ÙŠÙ†Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø¹Ø§Ø·ÙØ©
            profile = self.emotion_profiles.get(emotion, self.emotion_profiles['neutral'])
            
            # ØªØ¹Ø¯ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ø§Ù‚Ø©
            energy_factor = profile['energy']
            if energy_factor != 1.0:
                audio = audio + (20 * np.log10(energy_factor))
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø³Ù†
            audio.export(audio_path, format="wav")
            
        except Exception as e:
            print(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª: {e}")
    
    def create_voice_clone(self, reference_audio_path, text, output_path="cloned_voice.wav"):
        """Ø§Ø³ØªÙ†Ø³Ø§Ø® ØµÙˆØª Ù…Ù† Ù…Ù„Ù Ù…Ø±Ø¬Ø¹ÙŠ"""
        try:
            print("ğŸ­ Ø¨Ø¯Ø¡ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„ØµÙˆØª...")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
            reference_wav, sr = librosa.load(reference_audio_path, sr=22050)
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… XTTS Ù„Ù„Ø§Ø³ØªÙ†Ø³Ø§Ø®
            if hasattr(self.current_synthesizer, 'tts_with_vc'):
                cloned_wav = self.current_synthesizer.tts_with_vc(
                    text=text,
                    speaker_wav=reference_wav
                )
            else:
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¯Ø¹Ù… Ø§Ù„Ø§Ø³ØªÙ†Ø³Ø§Ø®ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                cloned_wav = self.current_synthesizer.tts(text)
            
            sf.write(output_path, cloned_wav, 22050)
            print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³ØªÙ†Ø³Ø® ÙÙŠ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„ØµÙˆØª: {e}")
            return None
    
    def analyze_voice_quality(self, audio_path):
        """ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù†Ø§ØªØ¬"""
        try:
            wav, sr = librosa.load(audio_path, sr=22050)
            
            analysis = {
                'duration': len(wav) / sr,
                'sample_rate': sr,
                'rms_energy': np.sqrt(np.mean(wav**2)),
                'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(wav)),
                'spectral_centroid': np.mean(librosa.feature.spectral_centroid(wav, sr=sr)),
                'naturalness_score': self._calculate_naturalness_score(wav, sr)
            }
            
            return analysis
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª: {e}")
            return None
    
    def _calculate_naturalness_score(self, wav, sr):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©"""
        # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ø¨Ø³Ø·Ø© Ù„ØªÙ‚ÙŠÙŠÙ… Ø·Ø¨ÙŠØ¹ÙŠØ© Ø§Ù„ØµÙˆØª
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        f0 = librosa.yin(wav, fmin=50, fmax=400)
        f0_variance = np.var(f0[f0 > 0])
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·ÙŠÙ
        spectral_rolloff = librosa.feature.spectral_rolloff(wav, sr=sr)
        spectral_variance = np.var(spectral_rolloff)
        
        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (0-1)
        naturalness = min(1.0, f0_variance / 1000 + spectral_variance / 10000)
        
        return naturalness

if __name__ == "__main__":
    tts = UltraNaturalTTS()
    
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©
    test_texts = [
        "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯!",
        "Ø£Ø´Ø¹Ø± Ø¨Ø³Ø¹Ø§Ø¯Ø© ÙƒØ¨ÙŠØ±Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…",
        "Ù„Ù„Ø£Ø³ÙØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨",
        "Ù‡Ø°Ø§ Ø±Ø§Ø¦Ø¹! Ù„Ù‚Ø¯ Ø­Ù‚Ù‚Øª Ù†ØªØ§Ø¦Ø¬ Ù…Ù…ØªØ§Ø²Ø©!"
    ]
    
    for i, text in enumerate(test_texts):
        output_file = f"test_ultra_natural_{i+1}.wav"
        tts.synthesize_ultra_natural(text, output_path=output_file)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality = tts.analyze_voice_quality(output_file)
        if quality:
            print(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù„Ù„Ù†Øµ {i+1}:")
            print(f"   Ø§Ù„Ù…Ø¯Ø©: {quality['duration']:.2f} Ø«Ø§Ù†ÙŠØ©")
            print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©: {quality['naturalness_score']:.2f}")
