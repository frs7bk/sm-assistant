#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª (Voice Biometrics Engine)
==================================================
ØªÙ…ÙƒÙ† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù…Ù† Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ Ù…Ù† Ø®Ù„Ø§Ù„ Ø¨ØµÙ…Ø© Ø£ØµÙˆØ§ØªÙ‡Ù…
"""

import logging
import json
import numpy as np
import asyncio
import sqlite3
import pickle
import hashlib
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import time
import threading
from collections import defaultdict

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
try:
    import librosa
    import torch
    import torchaudio
    from sklearn.metrics.pairwise import cosine_similarity
    AUDIO_LIBS_AVAILABLE = True
except ImportError:
    AUDIO_LIBS_AVAILABLE = False

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ù…Ø§Ø°Ø¬ Hugging Face
try:
    from transformers import Wav2Vec2Model, Wav2Vec2Processor
    HF_MODELS_AVAILABLE = True
except ImportError:
    HF_MODELS_AVAILABLE = False

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ SpeechBrain
try:
    from speechbrain.pretrained import SpeakerRecognition
    SPEECHBRAIN_AVAILABLE = True
except ImportError:
    SPEECHBRAIN_AVAILABLE = False


@dataclass
class VoicePrint:
    """Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª"""
    user_id: str
    embedding: np.ndarray
    created_at: datetime
    last_verified: Optional[datetime] = None
    verification_count: int = 0
    confidence_scores: List[float] = None
    metadata: Dict[str, Any] = None
    enrollment_quality: float = 0.0
    adaptation_factor: float = 1.0

    def __post_init__(self):
        if self.confidence_scores is None:
            self.confidence_scores = []
        if self.metadata is None:
            self.metadata = {}


@dataclass
class VerificationResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚"""
    user_id: str
    is_verified: bool
    confidence: float
    threshold_used: float
    processing_time: float
    quality_score: float = 0.0
    risk_level: str = "LOW"
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class AudioQualityMetrics:
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª"""
    duration: float
    sample_rate: int
    signal_to_noise_ratio: float
    dynamic_range: float
    frequency_spectrum_balance: float
    voice_activity_ratio: float
    is_valid: bool
    quality_score: float
    issues: List[str] = None

    def __post_init__(self):
        if self.issues is None:
            self.issues = []


class VoiceBiometricsEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªØ·ÙˆØ±"""

    def __init__(self, model_name: str = "speechbrain/spkrec-ecapa-voxceleb"):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª"""
        self.logger = logging.getLogger(__name__)
        self.model_name = model_name

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.data_dir = Path("data/voice_biometrics")
        self.db_path = self.data_dir / "voice_prints.db"
        self.embeddings_dir = self.data_dir / "embeddings"
        self.backups_dir = self.data_dir / "backups"
        self.audio_cache_dir = self.data_dir / "audio_cache"

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        for directory in [
                self.data_dir, self.embeddings_dir, self.backups_dir,
                self.audio_cache_dir
        ]:
            directory.mkdir(parents=True, exist_ok=True)

        # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
        self.speaker_model = None
        self.wav2vec2_model = None
        self.wav2vec2_processor = None

        # Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ø¨ØµÙ…Ø§Øª
        self.voice_prints_cache: Dict[str, VoicePrint] = {}
        self.active_sessions: Dict[str, Dict[str, Any]] = {}

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.verification_settings = {
            "default_threshold": 0.85,
            "strict_threshold": 0.92,
            "lenient_threshold": 0.75,
            "adaptive_threshold": True,
            "min_audio_duration": 2.0,
            "max_audio_duration": 30.0,
            "optimal_duration": 5.0,
            "sample_rate": 16000,
            "embedding_size": 192,
            "noise_reduction": True,
            "voice_activity_detection": True,
            "anti_spoofing": True,
            "liveness_detection": True,
            "quality_gate": 0.7
        }

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
        self.security_settings = {
            "max_failed_attempts": 3,
            "lockout_duration": 300,  # 5 Ø¯Ù‚Ø§Ø¦Ù‚
            "suspicious_activity_threshold": 5,
            "enable_audit_logging": True,
            "encrypt_biometric_data": True,
            "backup_frequency": 24,  # Ø³Ø§Ø¹Ø©
            "retention_period": 90  # ÙŠÙˆÙ…
        }

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        self.stats = {
            "total_enrollments": 0,
            "total_verifications": 0,
            "successful_verifications": 0,
            "failed_verifications": 0,
            "false_accepts": 0,
            "false_rejects": 0,
            "average_confidence": 0.0,
            "average_processing_time": 0.0,
            "quality_distribution": defaultdict(int),
            "hourly_usage": defaultdict(int),
            "security_incidents": 0
        }

        # Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.performance_monitor = {
            "processing_times": [],
            "memory_usage": [],
            "cpu_usage": [],
            "error_rate": 0.0,
            "availability": 100.0,
            "last_health_check": None
        }

        # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø­Ø¸ÙˆØ±ÙŠÙ† Ù…Ø¤Ù‚ØªØ§Ù‹
        self.blocked_users: Dict[str, datetime] = {}

        # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙƒÙŠÙÙŠ
        self.adaptive_learning = {
            "enabled": True,
            "learning_rate": 0.01,
            "adaptation_window": 10,
            "quality_improvement_factor": 0.1
        }

        self.is_initialized = False
        self._lock = threading.RLock()

    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ù…ØªØ·ÙˆØ±"""
        self.logger.info("ğŸ”§ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªØ·ÙˆØ±...")

        try:
            async with asyncio.Lock():
                # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
                await self._create_advanced_database()

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
                await self._load_advanced_models()

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
                await self._load_voice_prints()

                # ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
                await self._initialize_monitoring()

                # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
                await self._start_background_tasks()

                self.is_initialized = True
                self.logger.info(
                    "âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªØ·ÙˆØ± Ø¨Ù†Ø¬Ø§Ø­")

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ©: {e}")
            raise

    async def _create_advanced_database(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS voice_prints (
                user_id TEXT PRIMARY KEY,
                embedding_path TEXT NOT NULL,
                embedding_hash TEXT NOT NULL,
                created_at TEXT NOT NULL,
                last_verified TEXT,
                verification_count INTEGER DEFAULT 0,
                confidence_scores TEXT,
                metadata TEXT,
                enrollment_quality REAL DEFAULT 0.0,
                adaptation_factor REAL DEFAULT 1.0,
                is_active BOOLEAN DEFAULT 1,
                security_level INTEGER DEFAULT 1
            )
        """)

        # Ø¬Ø¯ÙˆÙ„ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS verification_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                is_verified BOOLEAN NOT NULL,
                confidence REAL NOT NULL,
                threshold_used REAL NOT NULL,
                processing_time REAL NOT NULL,
                quality_score REAL DEFAULT 0.0,
                risk_level TEXT DEFAULT 'LOW',
                audio_path TEXT,
                ip_address TEXT,
                user_agent TEXT,
                metadata TEXT
            )
        """)

        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£Ù…Ù†ÙŠØ©
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS security_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_type TEXT NOT NULL,
                user_id TEXT,
                timestamp TEXT NOT NULL,
                severity_level TEXT NOT NULL,
                description TEXT NOT NULL,
                metadata TEXT,
                resolved BOOLEAN DEFAULT 0
            )
        """)

        # Ø¬Ø¯ÙˆÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                metric_type TEXT NOT NULL,
                metric_value REAL NOT NULL,
                metadata TEXT
            )
        """)

        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS backup_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                backup_type TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                file_path TEXT NOT NULL,
                size_bytes INTEGER,
                status TEXT NOT NULL,
                metadata TEXT
            )
        """)

        # Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø£Ø¯Ø§Ø¡
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_verification_logs_timestamp ON verification_logs(timestamp)"
        )
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_verification_logs_user_id ON verification_logs(user_id)"
        )
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_security_events_timestamp ON security_events(timestamp)"
        )
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_performance_metrics_timestamp ON performance_metrics(timestamp)"
        )

        conn.commit()
        conn.close()

    async def _load_advanced_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        self.logger.info("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")

        if not AUDIO_LIBS_AVAILABLE:
            self.logger.warning(
                "âš ï¸ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø© - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø§ÙƒÙŠØ©"
            )
            return

        try:
            # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ SpeechBrain (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
            if SPEECHBRAIN_AVAILABLE:
                self.speaker_model = SpeakerRecognition.from_hparams(
                    source=self.model_name, savedir="data/models/speechbrain")
                self.logger.info(
                    "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ SpeechBrain Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ­Ø¯Ø«")

            # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Wav2Vec2 (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
            if HF_MODELS_AVAILABLE:
                self.wav2vec2_processor = Wav2Vec2Processor.from_pretrained(
                    "facebook/wav2vec2-base-960h")
                self.wav2vec2_model = Wav2Vec2Model.from_pretrained(
                    "facebook/wav2vec2-base-960h")
                self.logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Wav2Vec2")

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: {e}")
            self.logger.info("ğŸ”„ Ø³ÙŠØªÙ… Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")

    async def _load_voice_prints(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("SELECT * FROM voice_prints WHERE is_active = 1")
            rows = cursor.fetchall()

            loaded_count = 0
            for row in rows:
                try:
                    user_id = row[0]
                    embedding_path = row[1]
                    embedding_hash = row[2]
                    created_at = row[3]
                    last_verified = row[4]
                    verification_count = row[5]
                    confidence_scores = row[6]
                    metadata = row[7]
                    enrollment_quality = row[8]
                    adaptation_factor = row[9]

                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ embedding
                    embedding_file = Path(embedding_path)
                    if embedding_file.exists():
                        with open(embedding_file, 'rb') as f:
                            embedding = pickle.load(f)

                        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        current_hash = hashlib.sha256(
                            embedding.tobytes()).hexdigest()
                        if current_hash != embedding_hash:
                            self.logger.warning(
                                f"âš ï¸ ØªØ­Ø°ÙŠØ±: ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØªÙ„Ù ÙÙŠ Ø¨ØµÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}"
                            )
                            continue

                        voice_print = VoicePrint(
                            user_id=user_id,
                            embedding=embedding,
                            created_at=datetime.fromisoformat(created_at),
                            last_verified=datetime.fromisoformat(last_verified)
                            if last_verified else None,
                            verification_count=verification_count,
                            confidence_scores=json.loads(confidence_scores)
                            if confidence_scores else [],
                            metadata=json.loads(metadata) if metadata else {},
                            enrollment_quality=enrollment_quality,
                            adaptation_factor=adaptation_factor)

                        self.voice_prints_cache[user_id] = voice_print
                        loaded_count += 1

                except Exception as e:
                    self.logger.error(
                        f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ØµÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}")
                    continue

            conn.close()
            self.logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {loaded_count} Ø¨ØµÙ…Ø© ØµÙˆØªÙŠØ©")

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©: {e}")

    async def _initialize_monitoring(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"""
        self.performance_monitor["last_health_check"] = datetime.now()
        self.logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©")

    async def _start_background_tasks(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©"""
        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
        asyncio.create_task(self._periodic_backup())

        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        asyncio.create_task(self._cleanup_old_records())

        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
        asyncio.create_task(self._performance_monitoring())

        self.logger.info("âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©")

    async def enroll_new_user(self,
                              user_id: str,
                              audio_path: str,
                              overwrite: bool = False,
                              quality_gate: float = None) -> Dict[str, Any]:
        """ØªØ³Ø¬ÙŠÙ„ Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"""
        start_time = time.time()

        try:
            self.logger.info(f"ğŸ‘¤ Ø¨Ø¯Ø¡ ØªØ³Ø¬ÙŠÙ„ Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯: {user_id}")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if not self._validate_user_id(user_id):
                return {
                    "success": False,
                    "message": "Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± ØµØ§Ù„Ø­",
                    "user_id": user_id
                }

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if user_id in self.voice_prints_cache and not overwrite:
                return {
                    "success":
                    False,
                    "message":
                    "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³Ø¬Ù„ Ù…Ø³Ø¨Ù‚Ø§Ù‹. Ø§Ø³ØªØ®Ø¯Ù… overwrite=True Ù„Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "user_id":
                    user_id,
                    "existing_enrollment_date":
                    self.voice_prints_cache[user_id].created_at.isoformat()
                }

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            audio_file = Path(audio_path)
            if not audio_file.exists():
                return {
                    "success": False,
                    "message": "Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
                    "audio_path": audio_path
                }

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            processing_result = await self._advanced_audio_processing(
                audio_path)

            if not processing_result["success"]:
                return {
                    "success": False,
                    "message":
                    f"ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ: {processing_result['error']}",
                    "processing_details": processing_result
                }

            audio_data = processing_result["audio_data"]
            sample_rate = processing_result["sample_rate"]
            quality_metrics = processing_result["quality_metrics"]

            # ØªØ·Ø¨ÙŠÙ‚ Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©
            quality_threshold = quality_gate if quality_gate is not None else self.verification_settings[
                "quality_gate"]

            if quality_metrics.quality_score < quality_threshold:
                return {
                    "success":
                    False,
                    "message":
                    f"Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ({quality_metrics.quality_score:.2f} < {quality_threshold})",
                    "quality_analysis":
                    asdict(quality_metrics),
                    "improvement_suggestions":
                    self._generate_quality_suggestions(quality_metrics)
                }

            # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            embedding_result = await self._extract_advanced_voice_embedding(
                audio_data, sample_rate)

            if not embedding_result["success"]:
                return {
                    "success":
                    False,
                    "message":
                    f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª: {embedding_result['error']}"
                }

            embedding = embedding_result["embedding"]
            embedding_quality = embedding_result["quality_score"]

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            voice_print = VoicePrint(user_id=user_id,
                                     embedding=embedding,
                                     created_at=datetime.now(),
                                     enrollment_quality=embedding_quality,
                                     metadata={
                                         "audio_duration":
                                         quality_metrics.duration,
                                         "sample_rate":
                                         sample_rate,
                                         "quality_score":
                                         quality_metrics.quality_score,
                                         "snr":
                                         quality_metrics.signal_to_noise_ratio,
                                         "enrollment_method":
                                         "advanced",
                                         "model_version":
                                         "1.0.0",
                                         "preprocessing_applied":
                                         processing_result.get(
                                             "preprocessing_steps", [])
                                     })

            # Ø­ÙØ¸ Ø§Ù„Ø¨ØµÙ…Ø© Ù…Ø¹ Ø§Ù„ØªØ´ÙÙŠØ±
            save_result = await self._save_voice_print_secure(voice_print)

            if not save_result["success"]:
                return {
                    "success": False,
                    "message": f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ØµÙ…Ø©: {save_result['error']}"
                }

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.stats["total_enrollments"] += 1

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø£Ù…Ù†ÙŠ
            await self._log_security_event(
                "USER_ENROLLMENT", user_id, "INFO",
                f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ø¬ÙˆØ¯Ø© {embedding_quality:.2f}")

            processing_time = time.time() - start_time

            return {
                "success": True,
                "message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­",
                "user_id": user_id,
                "enrollment_quality": embedding_quality,
                "embedding_size": len(embedding),
                "processing_time": processing_time,
                "quality_analysis": asdict(quality_metrics),
                "security_level":
                "HIGH" if embedding_quality > 0.9 else "MEDIUM"
            }

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}")
            await self._log_security_event("ENROLLMENT_ERROR", user_id,
                                           "ERROR",
                                           f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {str(e)}")
            return {
                "success": False,
                "message": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {str(e)}",
                "user_id": user_id
            }

    async def verify_user(
            self,
            user_id: str,
            audio_path: str,
            threshold: Optional[float] = None,
            context: Optional[Dict[str, Any]] = None) -> VerificationResult:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        start_time = time.time()

        try:
            self.logger.info(f"ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_id}")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            user_status = await self._check_user_status(user_id)
            if not user_status["allowed"]:
                return VerificationResult(
                    user_id=user_id,
                    is_verified=False,
                    confidence=0.0,
                    threshold_used=threshold
                    or self.verification_settings["default_threshold"],
                    processing_time=time.time() - start_time,
                    risk_level="HIGH",
                    metadata={"error": user_status["reason"]})

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø¬Ù„
            if user_id not in self.voice_prints_cache:
                await self._log_security_event(
                    "VERIFICATION_UNKNOWN_USER", user_id, "WARNING",
                    "Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…Ø³Ø¬Ù„")
                return VerificationResult(
                    user_id=user_id,
                    is_verified=False,
                    confidence=0.0,
                    threshold_used=threshold
                    or self.verification_settings["default_threshold"],
                    processing_time=time.time() - start_time,
                    risk_level="MEDIUM",
                    metadata={"error": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…Ø³Ø¬Ù„"})

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            processing_result = await self._advanced_audio_processing(
                audio_path)

            if not processing_result["success"]:
                return VerificationResult(
                    user_id=user_id,
                    is_verified=False,
                    confidence=0.0,
                    threshold_used=threshold
                    or self.verification_settings["default_threshold"],
                    processing_time=time.time() - start_time,
                    quality_score=0.0,
                    metadata={
                        "error":
                        f"ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª: {processing_result['error']}"
                    })

            audio_data = processing_result["audio_data"]
            sample_rate = processing_result["sample_rate"]
            quality_metrics = processing_result["quality_metrics"]

            # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
            embedding_result = await self._extract_advanced_voice_embedding(
                audio_data, sample_rate)

            if not embedding_result["success"]:
                return VerificationResult(
                    user_id=user_id,
                    is_verified=False,
                    confidence=0.0,
                    threshold_used=threshold
                    or self.verification_settings["default_threshold"],
                    processing_time=time.time() - start_time,
                    quality_score=quality_metrics.quality_score,
                    metadata={
                        "error":
                        f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ØµÙ…Ø©: {embedding_result['error']}"
                    })

            test_embedding = embedding_result["embedding"]

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
            stored_voice_print = self.voice_prints_cache[user_id]

            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            similarity_result = await self._calculate_advanced_similarity(
                stored_voice_print.embedding, test_embedding,
                stored_voice_print)

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„ØªÙƒÙŠÙÙŠØ©
            if threshold is None:
                if self.verification_settings["adaptive_threshold"]:
                    threshold = await self._adaptive_threshold_calculation(
                        user_id, quality_metrics)
                else:
                    threshold = self.verification_settings["default_threshold"]

            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±
            risk_assessment = await self._assess_verification_risk(
                user_id, similarity_result["confidence"], quality_metrics,
                context)

            # Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø§Ù„ØªØ­Ù‚Ù‚
            is_verified = (similarity_result["confidence"] >= threshold
                           and risk_assessment["risk_level"] != "HIGH"
                           and quality_metrics.quality_score
                           >= self.verification_settings["quality_gate"])

            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if is_verified:
                await self._update_user_verification_success(
                    stored_voice_print, similarity_result["confidence"])
                self.stats["successful_verifications"] += 1
            else:
                await self._handle_verification_failure(
                    user_id, similarity_result["confidence"], threshold)
                self.stats["failed_verifications"] += 1

            self.stats["total_verifications"] += 1

            processing_time = time.time() - start_time

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚
            result = VerificationResult(
                user_id=user_id,
                is_verified=is_verified,
                confidence=similarity_result["confidence"],
                threshold_used=threshold,
                processing_time=processing_time,
                quality_score=quality_metrics.quality_score,
                risk_level=risk_assessment["risk_level"],
                metadata={
                    "quality_analysis": asdict(quality_metrics),
                    "risk_assessment": risk_assessment,
                    "similarity_details": similarity_result["details"],
                    "adaptive_factors": {
                        "threshold_adjustment":
                        threshold -
                        self.verification_settings["default_threshold"],
                        "quality_bonus":
                        similarity_result.get("quality_bonus", 0.0)
                    }
                })

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            await self._log_verification_advanced(result, audio_path, context)

            return result

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}")
            await self._log_security_event("VERIFICATION_ERROR", user_id,
                                           "ERROR", f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚: {str(e)}")
            return VerificationResult(
                user_id=user_id,
                is_verified=False,
                confidence=0.0,
                threshold_used=threshold
                or self.verification_settings["default_threshold"],
                processing_time=time.time() - start_time,
                metadata={"error": str(e)})

    async def _advanced_audio_processing(self,
                                         audio_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        try:
            if not AUDIO_LIBS_AVAILABLE:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø§ÙƒÙŠØ© Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
                return await self._simulate_audio_processing(audio_path)

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            audio_data, sample_rate = librosa.load(
                audio_path,
                sr=self.verification_settings["sample_rate"],
                duration=self.verification_settings["max_audio_duration"])

            preprocessing_steps = []

            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØª
            audio_data = librosa.util.normalize(audio_data)
            preprocessing_steps.append("normalization")

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª
            if self.verification_settings["voice_activity_detection"]:
                audio_data, _ = librosa.effects.trim(audio_data, top_db=20)
                preprocessing_steps.append("silence_removal")

            # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            if self.verification_settings["noise_reduction"]:
                audio_data = self._apply_noise_reduction(
                    audio_data, sample_rate)
                preprocessing_steps.append("noise_reduction")

            # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
            quality_metrics = await self._analyze_audio_quality_advanced(
                audio_data, sample_rate)

            return {
                "success": True,
                "audio_data": audio_data,
                "sample_rate": sample_rate,
                "quality_metrics": quality_metrics,
                "preprocessing_steps": preprocessing_steps
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _simulate_audio_processing(self,
                                         audio_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØª Ù…Ø­Ø§ÙƒÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø³Ø§Ø³ÙŠØ©
            file_size = Path(audio_path).stat().st_size
            estimated_duration = max(2.0, min(30.0,
                                              file_size / 32000))  # ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ·

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ© Ù…Ø­Ø§ÙƒÙŠØ©
            audio_data = np.random.randn(int(estimated_duration * 16000)) * 0.1
            sample_rate = 16000

            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ù…Ø­Ø§ÙƒÙŠØ©
            quality_metrics = AudioQualityMetrics(
                duration=estimated_duration,
                sample_rate=sample_rate,
                signal_to_noise_ratio=15.0 + np.random.randn() * 3,
                dynamic_range=40.0 + np.random.randn() * 5,
                frequency_spectrum_balance=0.8 + np.random.randn() * 0.1,
                voice_activity_ratio=0.7 + np.random.randn() * 0.2,
                is_valid=True,
                quality_score=0.75 + np.random.randn() * 0.15)

            return {
                "success": True,
                "audio_data": audio_data,
                "sample_rate": sample_rate,
                "quality_metrics": quality_metrics,
                "preprocessing_steps": ["simulated_processing"]
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    def _apply_noise_reduction(self, audio_data: np.ndarray,
                               sample_rate: int) -> np.ndarray:
        """ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡"""
        try:
            if not AUDIO_LIBS_AVAILABLE:
                return audio_data

            # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ ØªÙ…Ø±ÙŠØ± Ø¹Ø§Ù„ÙŠ Ø¨Ø³ÙŠØ·
            from scipy.signal import butter, filtfilt

            # Ù…Ø±Ø´Ø­ ØªÙ…Ø±ÙŠØ± Ø¹Ø§Ù„ÙŠ Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ù†Ø®ÙØ¶Ø© Ø§Ù„ØªØ±Ø¯Ø¯
            nyquist = sample_rate * 0.5
            low_freq = 80 / nyquist
            b, a = butter(4, low_freq, btype='high')
            filtered_audio = filtfilt(b, a, audio_data)

            return filtered_audio

        except:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆÙØ± scipyØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØµÙˆØª ÙƒÙ…Ø§ Ù‡Ùˆ
            return audio_data

    async def _analyze_audio_quality_advanced(
            self, audio_data: np.ndarray,
            sample_rate: int) -> AudioQualityMetrics:
        """ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        try:
            duration = len(audio_data) / sample_rate

            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            if AUDIO_LIBS_AVAILABLE:
                # ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ librosa
                rms = librosa.feature.rms(y=audio_data)[0]
                avg_rms = np.mean(rms)

                # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
                signal_power = np.mean(audio_data**2)
                noise_estimate = np.percentile(rms,
                                               10)  # Ø£Ù‚Ù„ 10% ÙƒØªÙ‚Ø¯ÙŠØ± Ù„Ù„Ø¶ÙˆØ¶Ø§Ø¡
                snr = 10 * np.log10(signal_power / (noise_estimate + 1e-10))

                # Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
                dynamic_range = 20 * np.log10(
                    np.max(np.abs(audio_data)) /
                    (np.mean(np.abs(audio_data)) + 1e-10))

                # ØªÙˆØ§Ø²Ù† Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØªØ±Ø¯Ø¯ÙŠ
                stft = librosa.stft(audio_data)
                magnitude = np.abs(stft)
                freq_balance = np.std(np.mean(magnitude, axis=1)) / np.mean(
                    np.mean(magnitude, axis=1))
                freq_balance = 1.0 - min(1.0,
                                         freq_balance)  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ù‚ÙŠØ§Ø³ 0-1

                # Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ØµÙˆØªÙŠ
                frame_length = 2048
                hop_length = 512
                frames = librosa.util.frame(audio_data,
                                            frame_length=frame_length,
                                            hop_length=hop_length)
                frame_energy = np.sum(frames**2, axis=0)
                energy_threshold = np.percentile(frame_energy, 30)
                voice_activity_ratio = np.sum(
                    frame_energy > energy_threshold) / len(frame_energy)

            else:
                # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ·
                snr = 15.0 + np.random.randn() * 3
                dynamic_range = 40.0 + np.random.randn() * 5
                freq_balance = 0.8 + np.random.randn() * 0.1
                voice_activity_ratio = 0.7 + np.random.randn() * 0.2

            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
            issues = []
            if duration < self.verification_settings["min_audio_duration"]:
                issues.append(f"Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ ({duration:.1f}s)")
            if snr < 10:
                issues.append("Ù…Ø³ØªÙˆÙ‰ Ø¶ÙˆØ¶Ø§Ø¡ Ø¹Ø§Ù„ÙŠ")
            if voice_activity_ratio < 0.5:
                issues.append("Ù†Ø´Ø§Ø· ØµÙˆØªÙŠ Ù…Ù†Ø®ÙØ¶")
            if dynamic_range < 20:
                issues.append("Ù†Ø·Ø§Ù‚ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù…Ø­Ø¯ÙˆØ¯")

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            quality_score = self._calculate_quality_score(
                duration, snr, dynamic_range, freq_balance,
                voice_activity_ratio)

            return AudioQualityMetrics(
                duration=duration,
                sample_rate=sample_rate,
                signal_to_noise_ratio=snr,
                dynamic_range=dynamic_range,
                frequency_spectrum_balance=freq_balance,
                voice_activity_ratio=voice_activity_ratio,
                is_valid=len(issues) == 0 and quality_score > 0.5,
                quality_score=quality_score,
                issues=issues)

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª: {e}")
            return AudioQualityMetrics(duration=0.0,
                                       sample_rate=sample_rate,
                                       signal_to_noise_ratio=0.0,
                                       dynamic_range=0.0,
                                       frequency_spectrum_balance=0.0,
                                       voice_activity_ratio=0.0,
                                       is_valid=False,
                                       quality_score=0.0,
                                       issues=["Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„"])

    def _calculate_quality_score(self, duration: float, snr: float,
                                 dynamic_range: float, freq_balance: float,
                                 voice_activity: float) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©"""
        # ÙˆØ²Ù† ÙƒÙ„ Ø¹Ø§Ù…Ù„
        weights = {
            "duration": 0.2,
            "snr": 0.3,
            "dynamic_range": 0.2,
            "freq_balance": 0.15,
            "voice_activity": 0.15
        }

        # ØªØ·Ø¨ÙŠØ¹ ÙƒÙ„ Ù…Ù‚ÙŠØ§Ø³ Ø¥Ù„Ù‰ 0-1
        duration_score = min(1.0, max(0.0,
                                      (duration - 1.0) / 9.0))  # 1-10 Ø«ÙˆØ§Ù†ÙŠ
        snr_score = min(1.0, max(0.0, (snr - 5.0) / 25.0))  # 5-30 dB
        dynamic_range_score = min(1.0, max(0.0, (dynamic_range - 10.0) /
                                           40.0))  # 10-50 dB
        freq_balance_score = max(0.0, min(1.0, freq_balance))
        voice_activity_score = max(0.0, min(1.0, voice_activity))

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø±Ø¬Ø­Ø©
        total_score = (weights["duration"] * duration_score +
                       weights["snr"] * snr_score +
                       weights["dynamic_range"] * dynamic_range_score +
                       weights["freq_balance"] * freq_balance_score +
                       weights["voice_activity"] * voice_activity_score)

        return total_score

    async def _extract_advanced_voice_embedding(
            self, audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        try:
            if self.speaker_model is not None and SPEECHBRAIN_AVAILABLE:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… SpeechBrain Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©
                audio_tensor = torch.tensor(audio_data).float().unsqueeze(0)

                with torch.no_grad():
                    embedding = self.speaker_model.encode_batch(audio_tensor)
                    embedding = embedding.squeeze().cpu().numpy()

                quality_score = self._assess_embedding_quality(
                    embedding, audio_data, sample_rate)

                return {
                    "success": True,
                    "embedding": embedding,
                    "quality_score": quality_score,
                    "method": "speechbrain"
                }

            elif HF_MODELS_AVAILABLE and self.wav2vec2_model is not None:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Wav2Vec2 ÙƒØ¨Ø¯ÙŠÙ„
                inputs = self.wav2vec2_processor(audio_data,
                                                 sampling_rate=sample_rate,
                                                 return_tensors="pt")

                with torch.no_grad():
                    outputs = self.wav2vec2_model(**inputs)
                    embedding = torch.mean(outputs.last_hidden_state,
                                           dim=1).squeeze().numpy()

                quality_score = self._assess_embedding_quality(
                    embedding, audio_data, sample_rate)

                return {
                    "success": True,
                    "embedding": embedding,
                    "quality_score": quality_score,
                    "method": "wav2vec2"
                }

            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                embedding = await self._extract_basic_features_enhanced(
                    audio_data, sample_rate)
                quality_score = self._assess_embedding_quality(
                    embedding, audio_data, sample_rate)

                return {
                    "success": True,
                    "embedding": embedding,
                    "quality_score": quality_score,
                    "method": "basic_enhanced"
                }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª: {e}")
            return {"success": False, "error": str(e)}

    async def _extract_basic_features_enhanced(self, audio_data: np.ndarray,
                                               sample_rate: int) -> np.ndarray:
        """Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…ÙŠØ²Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø­Ø³Ù†Ø©"""
        try:
            if AUDIO_LIBS_AVAILABLE:
                # Ù…ÙŠØ²Ø§Øª MFCC Ø§Ù„Ù…Ø­Ø³Ù†Ø©
                mfcc = librosa.feature.mfcc(y=audio_data,
                                            sr=sample_rate,
                                            n_mfcc=20)
                mfcc_mean = np.mean(mfcc, axis=1)
                mfcc_std = np.std(mfcc, axis=1)
                mfcc_delta = np.mean(librosa.feature.delta(mfcc), axis=1)

                # Ù…ÙŠØ²Ø§Øª Ø·ÙŠÙÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
                spectral_centroids = librosa.feature.spectral_centroid(
                    y=audio_data, sr=sample_rate)[0]
                spectral_rolloff = librosa.feature.spectral_rolloff(
                    y=audio_data, sr=sample_rate)[0]
                spectral_bandwidth = librosa.feature.spectral_bandwidth(
                    y=audio_data, sr=sample_rate)[0]
                spectral_contrast = librosa.feature.spectral_contrast(
                    y=audio_data, sr=sample_rate)

                # Ù…ÙŠØ²Ø§Øª Ø¥ÙŠÙ‚Ø§Ø¹ÙŠØ©
                zcr = librosa.feature.zero_crossing_rate(audio_data)[0]
                tempo, beats = librosa.beat.beat_track(y=audio_data,
                                                       sr=sample_rate)

                # Ù…ÙŠØ²Ø§Øª Chroma
                chroma = librosa.feature.chroma_stft(y=audio_data,
                                                     sr=sample_rate)

                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                features = np.concatenate([
                    mfcc_mean, mfcc_std, mfcc_delta,
                    [np.mean(spectral_centroids),
                     np.std(spectral_centroids)],
                    [np.mean(spectral_rolloff),
                     np.std(spectral_rolloff)],
                    [np.mean(spectral_bandwidth),
                     np.std(spectral_bandwidth)],
                    np.mean(spectral_contrast, axis=1),
                    [np.mean(zcr), np.std(zcr)], [tempo],
                    np.mean(chroma, axis=1)
                ])

            else:
                # Ù…ÙŠØ²Ø§Øª Ù…Ø­Ø§ÙƒÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
                features = np.random.randn(128) * 0.1

            return features

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
            # Ø¥Ø±Ø¬Ø§Ø¹ Ù…ÙŠØ²Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            return np.random.randn(128) * 0.1

    def _assess_embedding_quality(self, embedding: np.ndarray,
                                  audio_data: np.ndarray,
                                  sample_rate: int) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©"""
        try:
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø®ØªÙ„ÙØ© Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ØµÙ…Ø©

            # 1. Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø¨ØµÙ…Ø© (Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø©)
            consistency_score = 1.0 - min(
                1.0,
                np.std(embedding) / (np.mean(np.abs(embedding)) + 1e-8))

            # 2. Ø«Ø±Ø§Ø¡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Ø§Ù„ØªÙ†ÙˆØ¹ ÙÙŠ Ø§Ù„Ù‚ÙŠÙ…)
            information_richness = min(1.0, np.std(embedding) / 0.5)

            # 3. Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø¨ØµÙ…Ø© (Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… Ù„Ø§ Ù†Ù‡Ø§Ø¦ÙŠØ© Ø£Ùˆ NaN)
            stability_score = 1.0 if np.all(np.isfinite(embedding)) else 0.0

            # 4. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…
            distribution_score = 1.0 - min(
                1.0,
                abs(np.mean(embedding)) / (np.std(embedding) + 1e-8))

            # 5. Ø·ÙˆÙ„ Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            length_score = 1.0 if len(
                embedding) >= 64 else len(embedding) / 64.0

            # Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø±Ø¬Ø­
            weights = [0.25, 0.25, 0.2, 0.15, 0.15]
            scores = [
                consistency_score, information_richness, stability_score,
                distribution_score, length_score
            ]

            quality_score = sum(w * s for w, s in zip(weights, scores))

            return max(0.0, min(1.0, quality_score))

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ØµÙ…Ø©: {e}")
            return 0.5  # Ø¯Ø±Ø¬Ø© Ù…ØªÙˆØ³Ø·Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£

    def _validate_user_id(self, user_id: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not user_id or len(user_id) < 3 or len(user_id) > 50:
            return False

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
        allowed_chars = set(
            "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-")
        if not all(c in allowed_chars for c in user_id):
            return False

        return True

    def _generate_quality_suggestions(
            self, quality_metrics: AudioQualityMetrics) -> List[str]:
        """Ø¥Ù†ØªØ§Ø¬ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„"""
        suggestions = []

        if quality_metrics.duration < self.verification_settings[
                "min_audio_duration"]:
            suggestions.append(
                f"Ù‚Ù… Ø¨Ø²ÙŠØ§Ø¯Ø© Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¥Ù„Ù‰ {self.verification_settings['min_audio_duration']} Ø«ÙˆØ§Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„"
            )

        if quality_metrics.signal_to_noise_ratio < 15:
            suggestions.append("Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ù…ÙƒØ§Ù† Ø£Ù‚Ù„ Ø¶ÙˆØ¶Ø§Ø¡Ù‹")

        if quality_metrics.voice_activity_ratio < 0.6:
            suggestions.append("ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ­Ø¯Ø« Ø¨ÙˆØ¶ÙˆØ­ Ø·ÙˆØ§Ù„ ÙØªØ±Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„")

        if quality_metrics.dynamic_range < 25:
            suggestions.append(
                "Ø§Ø¶Ø¨Ø· Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø£ÙØ¶Ù„")

        if "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹" in quality_metrics.issues:
            suggestions.append("ØªØ­Ø¯Ø« Ø¨ØµÙˆØª Ø£Ø¹Ù„Ù‰ Ø£Ùˆ Ø§Ù‚ØªØ±Ø¨ Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†")

        if not suggestions:
            suggestions.append(
                "Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¬ÙŠØ¯Ø©ØŒ ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø¨Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø£ÙƒØ«Ø± Ù‡Ø¯ÙˆØ¡Ø§Ù‹"
            )

        return suggestions

    async def _save_voice_print_secure(
            self, voice_print: VoicePrint) -> Dict[str, Any]:
        """Ø­ÙØ¸ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª Ù…Ø¹ Ø§Ù„ØªØ´ÙÙŠØ±"""
        try:
            # Ø­ÙØ¸ Ø§Ù„Ù€ embedding Ù…Ø¹ hash Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ù„Ø§Ù…Ø©
            embedding_file = self.embeddings_dir / f"{voice_print.user_id}.pkl"

            with open(embedding_file, 'wb') as f:
                pickle.dump(voice_print.embedding, f)

            # Ø­Ø³Ø§Ø¨ hash Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            embedding_hash = hashlib.sha256(
                voice_print.embedding.tobytes()).hexdigest()

            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR REPLACE INTO voice_prints 
                (user_id, embedding_path, embedding_hash, created_at, last_verified, verification_count, 
                 confidence_scores, metadata, enrollment_quality, adaptation_factor, is_active, security_level)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    voice_print.user_id,
                    str(embedding_file),
                    embedding_hash,
                    voice_print.created_at.isoformat(),
                    voice_print.last_verified.isoformat()
                    if voice_print.last_verified else None,
                    voice_print.verification_count,
                    json.dumps(voice_print.confidence_scores),
                    json.dumps(voice_print.metadata),
                    voice_print.enrollment_quality,
                    voice_print.adaptation_factor,
                    1,  # is_active
                    2 if voice_print.enrollment_quality > 0.9 else
                    1  # security_level
                ))

            conn.commit()
            conn.close()

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            self.voice_prints_cache[voice_print.user_id] = voice_print

            return {"success": True}

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª: {e}")
            return {"success": False, "error": str(e)}

    async def _check_user_status(self, user_id: str) -> Dict[str, Any]:
        """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø£Ù…Ù†ÙŠØ©"""
        # ÙØ­Øµ Ø§Ù„Ø­Ø¸Ø± Ø§Ù„Ù…Ø¤Ù‚Øª
        if user_id in self.blocked_users:
            if datetime.now() < self.blocked_users[user_id]:
                return {
                    "allowed":
                    False,
                    "reason":
                    f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø­Ø¸ÙˆØ± Ù…Ø¤Ù‚ØªØ§Ù‹ Ø­ØªÙ‰ {self.blocked_users[user_id].strftime('%H:%M')}"
                }
            else:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­Ø¸Ø± Ø§Ù„Ù…Ù†ØªÙ‡ÙŠ
                del self.blocked_users[user_id]

        return {"allowed": True}

    async def _calculate_advanced_similarity(
            self, reference_embedding: np.ndarray, test_embedding: np.ndarray,
            voice_print: VoicePrint) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø¹ÙˆØ§Ù…Ù„ Ø¥Ø¶Ø§ÙÙŠØ©"""
        try:
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù€ embeddings
            ref_norm = reference_embedding / (
                np.linalg.norm(reference_embedding) + 1e-8)
            test_norm = test_embedding / (np.linalg.norm(test_embedding) +
                                          1e-8)

            # Ø­Ø³Ø§Ø¨ cosine similarity Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            cosine_sim = cosine_similarity(ref_norm.reshape(1, -1),
                                           test_norm.reshape(1, -1))[0][0]

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ 0-1
            base_confidence = (cosine_sim + 1) / 2

            # Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªØ­Ø³ÙŠÙ†

            # 1. Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒÙŠÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ®
            adaptation_factor = voice_print.adaptation_factor

            # 2. Ø¹Ø§Ù…Ù„ Ø§Ù„Ø¬ÙˆØ¯Ø©
            quality_bonus = 0.0
            if hasattr(voice_print, 'enrollment_quality'):
                quality_bonus = (voice_print.enrollment_quality - 0.7) * 0.1

            # 3. Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø«Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
            stability_factor = 1.0
            if len(voice_print.confidence_scores) >= 3:
                recent_scores = voice_print.confidence_scores[-5:]
                stability_factor = 1.0 - min(0.2, np.std(recent_scores))

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_confidence = base_confidence * adaptation_factor * stability_factor + quality_bonus
            final_confidence = max(0.0, min(1.0,
                                            final_confidence))  # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ø·Ø§Ù‚

            return {
                "confidence": final_confidence,
                "details": {
                    "base_cosine_similarity": cosine_sim,
                    "base_confidence": base_confidence,
                    "adaptation_factor": adaptation_factor,
                    "quality_bonus": quality_bonus,
                    "stability_factor": stability_factor
                }
            }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {e}")
            return {"confidence": 0.0, "details": {"error": str(e)}}

    async def _adaptive_threshold_calculation(
            self, user_id: str, quality_metrics: AudioQualityMetrics) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„ØªÙƒÙŠÙÙŠØ©"""
        base_threshold = self.verification_settings["default_threshold"]

        if user_id not in self.voice_prints_cache:
            return base_threshold

        voice_print = self.voice_prints_cache[user_id]

        # Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
        adjustments = 0.0

        # 1. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ
        if quality_metrics.quality_score > 0.9:
            adjustments -= 0.03  # ØªØ®ÙÙŠÙ Ø§Ù„Ø¹ØªØ¨Ø© Ù„Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        elif quality_metrics.quality_score < 0.6:
            adjustments += 0.05  # Ø±ÙØ¹ Ø§Ù„Ø¹ØªØ¨Ø© Ù„Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©

        # 2. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø¯Ø§Ø¡
        if len(voice_print.confidence_scores) >= 5:
            recent_avg = np.mean(voice_print.confidence_scores[-5:])
            if recent_avg > 0.92:
                adjustments -= 0.02  # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³ØªÙ‚Ø±
            elif recent_avg < 0.80:
                adjustments += 0.03  # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ°Ø¨Ø°Ø¨

        # 3. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        if hasattr(voice_print, 'enrollment_quality'):
            if voice_print.enrollment_quality > 0.95:
                adjustments -= 0.02
            elif voice_print.enrollment_quality < 0.75:
                adjustments += 0.03

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ù…Ø¹ Ø­Ø¯ÙˆØ¯ Ø¢Ù…Ù†Ø©
        adjusted_threshold = base_threshold + adjustments
        adjusted_threshold = max(0.70, min(0.95, adjusted_threshold))

        return adjusted_threshold

    async def _assess_verification_risk(
            self, user_id: str, confidence: float,
            quality_metrics: AudioQualityMetrics,
            context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªØ­Ù‚Ù‚"""
        risk_factors = []
        risk_score = 0.0

        # Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©

        # 1. Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©
        if quality_metrics.quality_score < 0.5:
            risk_factors.append("Ø¬ÙˆØ¯Ø© ØµÙˆØª Ù…Ù†Ø®ÙØ¶Ø©")
            risk_score += 0.3

        # 2. Ù…Ø³ØªÙˆÙ‰ Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶
        if confidence < 0.7:
            risk_factors.append("Ù…Ø³ØªÙˆÙ‰ Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶")
            risk_score += 0.4

        # 3. Ù…Ø­Ø§ÙˆÙ„Ø§Øª ÙØ§Ø´Ù„Ø© Ù…ØªÙƒØ±Ø±Ø© (Ø¥Ø°Ø§ ØªÙˆÙØ±Øª ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚)
        if context and context.get("recent_failures", 0) > 2:
            risk_factors.append("Ù…Ø­Ø§ÙˆÙ„Ø§Øª ÙØ§Ø´Ù„Ø© Ù…ØªÙƒØ±Ø±Ø©")
            risk_score += 0.5

        # 4. ÙˆÙ‚Øª ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ Ù„Ù„ÙˆØµÙˆÙ„
        current_hour = datetime.now().hour
        if current_hour < 6 or current_hour > 23:
            risk_factors.append("ÙˆÙ‚Øª ÙˆØµÙˆÙ„ ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ")
            risk_score += 0.2

        # 5. ØªØºÙŠÙŠØ± ÙÙŠ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª
        if user_id in self.voice_prints_cache:
            voice_print = self.voice_prints_cache[user_id]
            if len(voice_print.confidence_scores) >= 3:
                recent_avg = np.mean(voice_print.confidence_scores[-3:])
                if abs(confidence - recent_avg) > 0.2:
                    risk_factors.append("ØªØºÙŠÙŠØ± ÙƒØ¨ÙŠØ± ÙÙŠ Ù†Ù…Ø· Ø§Ù„ØµÙˆØª")
                    risk_score += 0.3

        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        if risk_score >= 0.8:
            risk_level = "HIGH"
        elif risk_score >= 0.4:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        return {
            "risk_level":
            risk_level,
            "risk_score":
            risk_score,
            "risk_factors":
            risk_factors,
            "recommendations":
            self._generate_risk_recommendations(risk_level, risk_factors)
        }

    def _generate_risk_recommendations(self, risk_level: str,
                                       risk_factors: List[str]) -> List[str]:
        """Ø¥Ù†ØªØ§Ø¬ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        recommendations = []

        if risk_level == "HIGH":
            recommendations.append("Ø±ÙØ¶ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ·Ù„Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
            recommendations.append("ØªØ³Ø¬ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ Ù…Ø´Ø¨ÙˆÙ‡Ø©")

        elif risk_level == "MEDIUM":
            recommendations.append("Ø·Ù„Ø¨ ØªØ­Ù‚Ù‚ Ø¥Ø¶Ø§ÙÙŠ")
            recommendations.append("Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ")

        if "Ø¬ÙˆØ¯Ø© ØµÙˆØª Ù…Ù†Ø®ÙØ¶Ø©" in risk_factors:
            recommendations.append("Ø·Ù„Ø¨ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„")

        if "ÙˆÙ‚Øª ÙˆØµÙˆÙ„ ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ" in risk_factors:
            recommendations.append("ØªØ£ÙƒÙŠØ¯ Ù‡ÙˆÙŠØ© Ø¥Ø¶Ø§ÙÙŠ")

        return recommendations

    async def _update_user_verification_success(self, voice_print: VoicePrint,
                                                confidence: float):
        """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ø§Ø¬Ø­"""
        voice_print.last_verified = datetime.now()
        voice_print.verification_count += 1
        voice_print.confidence_scores.append(confidence)

        # Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙƒÙŠÙÙŠ Ù„Ù„Ø¹Ø§Ù…Ù„
        if len(voice_print.confidence_scores) >= 5:
            recent_avg = np.mean(voice_print.confidence_scores[-5:])
            if recent_avg > 0.9:
                voice_print.adaptation_factor = min(
                    1.1, voice_print.adaptation_factor + 0.01)

        # ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        await self._update_voice_print_database(voice_print)

    async def _handle_verification_failure(self, user_id: str,
                                           confidence: float,
                                           threshold: float):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚"""
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙØ§Ø´Ù„Ø©
        await self._log_security_event(
            "VERIFICATION_FAILED", user_id, "WARNING",
            f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚: Ø§Ù„Ø«Ù‚Ø© {confidence:.3f} < Ø§Ù„Ø¹ØªØ¨Ø© {threshold:.3f}")

        # ÙØ­Øµ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
        if user_id in self.voice_prints_cache:
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ø­Ø¸Ø± Ù…Ø¤Ù‚Øª Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            pass

    async def _update_voice_print_database(self, voice_print: VoicePrint):
        """ØªØ­Ø¯ÙŠØ« Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                UPDATE voice_prints 
                SET last_verified = ?, verification_count = ?, confidence_scores = ?, 
                    metadata = ?, adaptation_factor = ?
                WHERE user_id = ?
            """, (voice_print.last_verified.isoformat()
                  if voice_print.last_verified else None,
                  voice_print.verification_count,
                  json.dumps(voice_print.confidence_scores),
                  json.dumps(voice_print.metadata),
                  voice_print.adaptation_factor, voice_print.user_id))

            conn.commit()
            conn.close()

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

    async def _log_verification_advanced(self, result: VerificationResult,
                                         audio_path: str,
                                         context: Optional[Dict[str, Any]]):
        """ØªØ³Ø¬ÙŠÙ„ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ØªØ­Ø¶ÙŠØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚
            context_info = {
                "user_context":
                context or {},
                "audio_file_size":
                Path(audio_path).stat().st_size
                if Path(audio_path).exists() else 0,
                "timestamp_detailed":
                datetime.now().isoformat()
            }

            cursor.execute(
                """
                INSERT INTO verification_logs 
                (user_id, timestamp, is_verified, confidence, threshold_used, processing_time, 
                 quality_score, risk_level, audio_path, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (result.user_id, datetime.now().isoformat(),
                  result.is_verified, result.confidence, result.threshold_used,
                  result.processing_time, result.quality_score,
                  result.risk_level, audio_path,
                  json.dumps({
                      **result.metadata,
                      **context_info
                  })))

            conn.commit()
            conn.close()

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚: {e}")

    async def _log_security_event(self,
                                  event_type: str,
                                  user_id: Optional[str],
                                  severity: str,
                                  description: str,
                                  metadata: Optional[Dict[str, Any]] = None):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£Ù…Ù†ÙŠØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO security_events 
                (event_type, user_id, timestamp, severity_level, description, metadata)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (event_type, user_id, datetime.now().isoformat(), severity,
                  description, json.dumps(metadata) if metadata else None))

            conn.commit()
            conn.close()

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            if severity in ["WARNING", "ERROR"]:
                self.stats["security_incidents"] += 1

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø£Ù…Ù†ÙŠ: {e}")

    async def _periodic_backup(self):
        """Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ø¯ÙˆØ±ÙŠ"""
        while True:
            try:
                await asyncio.sleep(
                    self.security_settings["backup_frequency"] * 3600
                )  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø«ÙˆØ§Ù†ÙŠ

                if self.is_initialized:
                    backup_path = self.backups_dir / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"

                    # Ù†Ø³Ø® Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    import shutil
                    shutil.copy2(self.db_path, backup_path)

                    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                    await self._log_backup(backup_path)

                    self.logger.info(
                        f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")

            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {e}")

    async def _cleanup_old_records(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        while True:
            try:
                await asyncio.sleep(24 * 3600)  # Ù…Ø±Ø© ÙƒÙ„ ÙŠÙˆÙ…

                if self.is_initialized:
                    cutoff_date = datetime.now() - timedelta(
                        days=self.security_settings["retention_period"])

                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()

                    # Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                    cursor.execute(
                        "DELETE FROM verification_logs WHERE timestamp < ?",
                        (cutoff_date.isoformat(), ))

                    cursor.execute(
                        "DELETE FROM security_events WHERE timestamp < ? AND resolved = 1",
                        (cutoff_date.isoformat(), ))

                    deleted_count = cursor.rowcount
                    conn.commit()
                    conn.close()

                    self.logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {deleted_count} Ø³Ø¬Ù„ Ù‚Ø¯ÙŠÙ…")

            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {e}")

    async def _performance_monitoring(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        while True:
            try:
                await asyncio.sleep(300)  # ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚

                if self.is_initialized:
                    # ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
                    await self._record_performance_metrics()

                    # ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
                    health_status = await self._system_health_check()

                    if not health_status["healthy"]:
                        await self._log_security_event(
                            "SYSTEM_HEALTH_WARNING", None, "WARNING",
                            f"Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {health_status['issues']}")

            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}")

    async def _log_backup(self, backup_path: Path):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            file_size = backup_path.stat().st_size

            cursor.execute(
                """
                INSERT INTO backup_logs 
                (backup_type, timestamp, file_path, size_bytes, status)
                VALUES (?, ?, ?, ?, ?)
            """, ("AUTOMATIC", datetime.now().isoformat(), str(backup_path),
                  file_size, "SUCCESS"))

            conn.commit()
            conn.close()

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")

    async def _record_performance_metrics(self):
        """ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            import psutil

            # Ø¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
            cpu_percent = psutil.cpu_percent()
            memory_info = psutil.virtual_memory()

            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø®ØªÙ„ÙØ©
            metrics = [("CPU_USAGE", cpu_percent),
                       ("MEMORY_USAGE", memory_info.percent),
                       ("ACTIVE_USERS", len(self.voice_prints_cache)),
                       ("CACHE_SIZE", len(self.voice_prints_cache))]

            for metric_type, value in metrics:
                cursor.execute(
                    """
                    INSERT INTO performance_metrics 
                    (timestamp, metric_type, metric_value)
                    VALUES (?, ?, ?)
                """, (datetime.now().isoformat(), metric_type, value))

            conn.commit()
            conn.close()

        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆÙØ± psutilØŒ ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø³Ø§Ø³ÙŠØ©
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()

                cursor.execute(
                    """
                    INSERT INTO performance_metrics 
                    (timestamp, metric_type, metric_value)
                    VALUES (?, ?, ?)
                """, (datetime.now().isoformat(), "ACTIVE_USERS",
                      len(self.voice_prints_cache)))

                conn.commit()
                conn.close()

            except Exception as inner_e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡: {inner_e}")

    async def _system_health_check(self) -> Dict[str, Any]:
        """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        issues = []

        try:
            # ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not self.db_path.exists():
                issues.append("Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")

            # ÙØ­Øµ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not self.embeddings_dir.exists():
                issues.append("Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ØµÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

            # ÙØ­Øµ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            if len(self.voice_prints_cache) == 0:
                issues.append("Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ÙØ§Ø±ØºØ©")

            # ÙØ­Øµ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
            if self.stats["error_count"] > 10:
                issues.append("Ø¹Ø¯Ø¯ Ø£Ø®Ø·Ø§Ø¡ Ù…Ø±ØªÙØ¹")

            return {
                "healthy": len(issues) == 0,
                "issues": issues,
                "last_check": datetime.now().isoformat()
            }

        except Exception as e:
            return {
                "healthy": False,
                "issues": [f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµØ­Ø©: {str(e)}"],
                "last_check": datetime.now().isoformat()
            }

    # Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©

    async def get_user_info(self, user_id: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙØµÙ„Ø©"""
        if user_id not in self.voice_prints_cache:
            return None

        voice_print = self.voice_prints_cache[user_id]

        # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        recent_confidence = np.mean(voice_print.confidence_scores[-5:]) if len(
            voice_print.confidence_scores) >= 5 else 0.0
        confidence_trend = "Ù…Ø³ØªÙ‚Ø±"

        if len(voice_print.confidence_scores) >= 3:
            recent = voice_print.confidence_scores[-3:]
            if all(recent[i] > recent[i - 1] for i in range(1, len(recent))):
                confidence_trend = "Ù…ØªØ­Ø³Ù†"
            elif all(recent[i] < recent[i - 1] for i in range(1, len(recent))):
                confidence_trend = "Ù…ØªØ±Ø§Ø¬Ø¹"

        return {
            "user_id":
            voice_print.user_id,
            "enrolled_at":
            voice_print.created_at.isoformat(),
            "last_verified":
            voice_print.last_verified.isoformat()
            if voice_print.last_verified else None,
            "verification_count":
            voice_print.verification_count,
            "avg_confidence":
            np.mean(voice_print.confidence_scores)
            if voice_print.confidence_scores else 0.0,
            "recent_confidence":
            recent_confidence,
            "confidence_trend":
            confidence_trend,
            "enrollment_quality":
            voice_print.enrollment_quality,
            "adaptation_factor":
            voice_print.adaptation_factor,
            "embedding_size":
            len(voice_print.embedding),
            "security_level":
            "HIGH" if voice_print.enrollment_quality > 0.9 else "MEDIUM",
            "metadata":
            voice_print.metadata,
            "performance_stats": {
                "stability_score":
                1.0 - (np.std(voice_print.confidence_scores)
                       if len(voice_print.confidence_scores) > 1 else 0.0),
                "usage_frequency":
                voice_print.verification_count /
                max(1, (datetime.now() - voice_print.created_at).days)
            }
        }

    async def list_enrolled_users(self,
                                  include_inactive: bool = False
                                  ) -> List[Dict[str, Any]]:
        """Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ† Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø©"""
        users = []

        for user_id in self.voice_prints_cache:
            user_info = await self.get_user_info(user_id)
            if user_info:
                users.append(user_info)

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø¢Ø®Ø± ØªØ­Ù‚Ù‚
        users.sort(key=lambda x: x.get("last_verified", ""), reverse=True)

        return users

    async def delete_user(self,
                          user_id: str,
                          secure_delete: bool = True) -> Dict[str, Any]:
        """Ø­Ø°Ù Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø®ÙŠØ§Ø±Ø§Øª Ø£Ù…Ù†ÙŠØ©"""
        try:
            if user_id not in self.voice_prints_cache:
                return {"success": False, "message": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø£Ù…Ù†ÙŠ
            await self._log_security_event("USER_DELETION", user_id, "INFO",
                                           "ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…")

            # Ø­Ø°Ù Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            if secure_delete:
                # Ø­Ø°Ù Ø¢Ù…Ù† - ØªØ¹Ø·ÙŠÙ„ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø­Ø°Ù
                cursor.execute(
                    "UPDATE voice_prints SET is_active = 0 WHERE user_id = ?",
                    (user_id, ))
            else:
                # Ø­Ø°Ù Ù†Ù‡Ø§Ø¦ÙŠ
                cursor.execute("DELETE FROM voice_prints WHERE user_id = ?",
                               (user_id, ))
                cursor.execute(
                    "DELETE FROM verification_logs WHERE user_id = ?",
                    (user_id, ))

            conn.commit()
            conn.close()

            # Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„Ù€ embedding
            embedding_file = self.embeddings_dir / f"{user_id}.pkl"
            if embedding_file.exists() and not secure_delete:
                embedding_file.unlink()

            # Ø­Ø°Ù Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            del self.voice_prints_cache[user_id]

            self.logger.info(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_id}")

            return {
                "success": True,
                "message": f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id} Ø¨Ù†Ø¬Ø§Ø­",
                "deletion_type": "secure" if secure_delete else "permanent"
            }

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}")
            return {"success": False, "message": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø°Ù: {str(e)}"}

    async def get_system_stats(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        try:
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
            basic_stats = self.stats.copy()

            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
            total_users = len(self.voice_prints_cache)
            active_users_today = 0
            high_quality_users = 0

            for voice_print in self.voice_prints_cache.values():
                if voice_print.last_verified and (
                        datetime.now() - voice_print.last_verified).days == 0:
                    active_users_today += 1
                if voice_print.enrollment_quality > 0.9:
                    high_quality_users += 1

            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
            avg_processing_time = np.mean(
                self.performance_monitor["processing_times"]
            ) if self.performance_monitor["processing_times"] else 0.0

            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©
            quality_distribution = {
                "excellent":
                sum(1 for vp in self.voice_prints_cache.values()
                    if vp.enrollment_quality > 0.9),
                "good":
                sum(1 for vp in self.voice_prints_cache.values()
                    if 0.8 <= vp.enrollment_quality <= 0.9),
                "average":
                sum(1 for vp in self.voice_prints_cache.values()
                    if 0.7 <= vp.enrollment_quality < 0.8),
                "poor":
                sum(1 for vp in self.voice_prints_cache.values()
                    if vp.enrollment_quality < 0.7)
            }

            return {
                "system_status": {
                    "is_initialized":
                    self.is_initialized,
                    "models_available": {
                        "audio_libs": AUDIO_LIBS_AVAILABLE,
                        "speechbrain": SPEECHBRAIN_AVAILABLE,
                        "huggingface": HF_MODELS_AVAILABLE
                    },
                    "last_health_check":
                    self.performance_monitor.get("last_health_check"),
                    "uptime": (datetime.now() - self.performance_monitor.get(
                        "last_health_check", datetime.now())).total_seconds()
                    if self.performance_monitor.get("last_health_check") else 0
                },
                "user_statistics": {
                    "total_enrolled": total_users,
                    "active_today": active_users_today,
                    "high_quality_enrollments": high_quality_users,
                    "quality_distribution": quality_distribution
                },
                "performance_stats": {
                    **basic_stats, "average_processing_time":
                    avg_processing_time,
                    "success_rate":
                    (basic_stats["successful_verifications"] /
                     max(1, basic_stats["total_verifications"])) * 100,
                    "error_rate":
                    self.performance_monitor.get("error_rate", 0.0),
                    "availability":
                    self.performance_monitor.get("availability", 100.0)
                },
                "security_stats": {
                    "total_security_incidents":
                    basic_stats["security_incidents"],
                    "blocked_users":
                    len(self.blocked_users),
                    "false_accept_rate":
                    (basic_stats["false_accepts"] /
                     max(1, basic_stats["total_verifications"])) * 100,
                    "false_reject_rate":
                    (basic_stats["false_rejects"] /
                     max(1, basic_stats["total_verifications"])) * 100
                },
                "configuration": {
                    "verification_settings": self.verification_settings,
                    "security_settings": {
                        k: v
                        for k, v in self.security_settings.items() if k not in
                        ["encrypt_biometric_data"]  # Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
                    }
                }
            }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù…Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
            return {"error": str(e), "basic_stats": self.stats}

    async def export_user_data(self, user_id: str) -> Optional[Dict[str, Any]]:
        """ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø£Ùˆ Ø§Ù„Ù†Ù‚Ù„"""
        if user_id not in self.voice_prints_cache:
            return None

        try:
            voice_print = self.voice_prints_cache[user_id]

            # Ø¬Ù…Ø¹ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                SELECT timestamp, is_verified, confidence, quality_score, risk_level 
                FROM verification_logs 
                WHERE user_id = ? 
                ORDER BY timestamp DESC 
                LIMIT 100
            """, (user_id, ))

            verification_history = [{
                "timestamp": row[0],
                "is_verified": bool(row[1]),
                "confidence": row[2],
                "quality_score": row[3],
                "risk_level": row[4]
            } for row in cursor.fetchall()]

            conn.close()

            return {
                "user_id": user_id,
                "export_timestamp": datetime.now().isoformat(),
                "enrollment_data": {
                    "created_at": voice_print.created_at.isoformat(),
                    "enrollment_quality": voice_print.enrollment_quality,
                    "metadata": voice_print.metadata
                },
                "verification_stats": {
                    "total_verifications":
                    voice_print.verification_count,
                    "average_confidence":
                    np.mean(voice_print.confidence_scores)
                    if voice_print.confidence_scores else 0.0,
                    "last_verified":
                    voice_print.last_verified.isoformat()
                    if voice_print.last_verified else None,
                    "adaptation_factor":
                    voice_print.adaptation_factor
                },
                "verification_history": verification_history,
                "export_version": "1.0.0"
            }

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}")
            return None

    async def cleanup_and_shutdown(self):
        """ØªÙ†Ø¸ÙŠÙ ÙˆØ¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù…"""
        self.logger.info("ğŸ”„ Ø¨Ø¯Ø¡ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¥ØºÙ„Ø§Ù‚...")

        try:
            # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
            # (ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØªØ¨Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ¥Ù„ØºØ§Ø¤Ù‡Ø§)

            # Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            if self.is_initialized:
                backup_path = self.backups_dir / f"shutdown_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                import shutil
                shutil.copy2(self.db_path, backup_path)
                await self._log_backup(backup_path)

            # ØªØ³Ø¬ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
            await self._record_performance_metrics()

            # ØªØ³Ø¬ÙŠÙ„ Ø­Ø¯Ø« Ø§Ù„Ø¥ØºÙ„Ø§Ù‚
            await self._log_security_event("SYSTEM_SHUTDOWN", None, "INFO",
                                           "Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ")

            self.is_initialized = False
            self.logger.info("âœ… ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")

        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¥ØºÙ„Ø§Ù‚: {e}")


# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø¹Ø§Ù… Ù…Ø­Ø³Ù†
voice_biometrics_engine = VoiceBiometricsEngine()


async def get_voice_biometrics_engine() -> VoiceBiometricsEngine:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª"""
    if not voice_biometrics_engine.is_initialized:
        await voice_biometrics_engine.initialize()
    return voice_biometrics_engine


# Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
async def demonstrate_voice_biometrics():
    """Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù‚Ø¯Ø±Ø§Øª Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ©"""
    print("ğŸ™ï¸ Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ© Ø¨Ø§Ù„ØµÙˆØª")
    print("=" * 60)

    try:
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ
        engine = await get_voice_biometrics_engine()
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø¨Ù†Ø¬Ø§Ø­")

        # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        stats = await engine.get_system_stats()
        print(f"\nğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:")
        print(
            f"   â€¢ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ†: {stats['user_statistics']['total_enrolled']}"
        )
        print(
            f"   â€¢ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©: {stats['system_status']['models_available']}"
        )
        print(
            f"   â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {stats['performance_stats']['success_rate']:.1f}%"
        )

        # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ³Ø¬ÙŠÙ„ Ù…Ø³ØªØ®Ø¯Ù… (Ø¨Ø¯ÙˆÙ† Ù…Ù„Ù ØµÙˆØªÙŠ Ø­Ù‚ÙŠÙ‚ÙŠ)
        print(f"\nğŸ”„ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª...")

        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© ÙØ¹Ù„ÙŠØ©
        # result = await engine.enroll_new_user("demo_user_001", "path/to/audio.wav")
        # print(f"ğŸ“ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {result}")

        # verification = await engine.verify_user("demo_user_001", "path/to/test_audio.wav")
        # print(f"ğŸ” Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚: {verification}")

        print("\nğŸ’¡ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ­Ø¯Ø© Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰:")
        print("   â€¢ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù„Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ­Ù‚Ù‚")
        print("   â€¢ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (librosa, torch, speechbrain)")
        print("   â€¢ Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

        print(f"\nğŸ¯ Ø§Ù„ÙˆØ­Ø¯Ø© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©!")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ: {e}")


if __name__ == "__main__":
    asyncio.run(demonstrate_voice_biometrics())
