
import numpy as np
import librosa
import torch
import soundfile as sf
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cosine
import pickle
import os
import json
from datetime import datetime
import sqlite3
import hashlib

class VoiceBiometricsEngine:
    """
    Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªÙ…ÙŠÙŠØ² Ø¨ÙŠÙ† Ø§Ù„Ø£ØµÙˆØ§Øª ÙˆØ§Ù„Ø¨ØµÙ…Ø© Ø§Ù„ØµÙˆØªÙŠØ©
    ÙŠÙ…ÙƒÙ†Ù‡:
    - Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† Ø§Ù„Ù…Ø®ØªÙ„ÙÙŠÙ†
    - Ø¥Ù†Ø´Ø§Ø¡ Ø¨ØµÙ…Ø§Øª ØµÙˆØªÙŠØ© ÙØ±ÙŠØ¯Ø©
    - ÙƒØ´Ù Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©
    - ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª Ø§Ù„ÙØ±ÙŠØ¯Ø©
    """
    
    def __init__(self, db_path="voice_profiles.db"):
        print("ğŸ¤ ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        
        self.db_path = db_path
        self.sample_rate = 16000
        self.n_mfcc = 13
        self.n_components = 32  # Ø¹Ø¯Ø¯ Ù…ÙƒÙˆÙ†Ø§Øª GMM
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._init_database()
        
        # Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ
        self.scaler = StandardScaler()
        self.voice_profiles = {}
        self.is_trained = False
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒØ´Ù Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø²ÙŠÙ
        self.deepfake_threshold = 0.7
        
        # Ø®ØµØ§Ø¦Øµ ØµÙˆØªÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
        self.voice_features = [
            'mfcc', 'chroma', 'spectral_centroid', 'spectral_rolloff',
            'zero_crossing_rate', 'pitch', 'formants', 'jitter', 'shimmer'
        ]
        
        print("âœ… Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØªÙŠ Ø¬Ø§Ù‡Ø²!")
    
    def _init_database(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS voice_profiles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                speaker_id TEXT UNIQUE,
                speaker_name TEXT,
                voice_signature BLOB,
                features_json TEXT,
                recordings_count INTEGER DEFAULT 0,
                created_date TEXT,
                last_updated TEXT,
                confidence_score REAL
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS voice_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT,
                speaker_id TEXT,
                audio_path TEXT,
                recognition_confidence REAL,
                timestamp TEXT,
                features_extracted TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def extract_voice_features(self, audio_path):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            y, sr = librosa.load(audio_path, sr=self.sample_rate)
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª
            y_trimmed, _ = librosa.effects.trim(y, top_db=20)
            
            if len(y_trimmed) < sr * 0.5:  # Ø£Ù‚Ù„ Ù…Ù† Ù†ØµÙ Ø«Ø§Ù†ÙŠØ©
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹")
            
            features = {}
            
            # MFCC (Ø§Ù„Ø£Ù‡Ù… Ù„Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØªÙŠ)
            mfcc = librosa.feature.mfcc(y=y_trimmed, sr=sr, n_mfcc=self.n_mfcc)
            features['mfcc_mean'] = np.mean(mfcc, axis=1)
            features['mfcc_std'] = np.std(mfcc, axis=1)
            features['mfcc_delta'] = np.mean(librosa.feature.delta(mfcc), axis=1)
            
            # Chroma features
            chroma = librosa.feature.chroma_stft(y=y_trimmed, sr=sr)
            features['chroma_mean'] = np.mean(chroma, axis=1)
            features['chroma_std'] = np.std(chroma, axis=1)
            
            # Spectral features
            spectral_centroids = librosa.feature.spectral_centroid(y=y_trimmed, sr=sr)[0]
            features['spectral_centroid_mean'] = np.mean(spectral_centroids)
            features['spectral_centroid_std'] = np.std(spectral_centroids)
            
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y_trimmed, sr=sr)[0]
            features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)
            
            # Zero crossing rate
            zcr = librosa.feature.zero_crossing_rate(y_trimmed)[0]
            features['zcr_mean'] = np.mean(zcr)
            features['zcr_std'] = np.std(zcr)
            
            # Pitch estimation
            pitches, magnitudes = librosa.core.piptrack(y=y_trimmed, sr=sr)
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_values.append(pitch)
            
            if pitch_values:
                features['pitch_mean'] = np.mean(pitch_values)
                features['pitch_std'] = np.std(pitch_values)
                features['pitch_min'] = np.min(pitch_values)
                features['pitch_max'] = np.max(pitch_values)
            else:
                features['pitch_mean'] = 0
                features['pitch_std'] = 0
                features['pitch_min'] = 0
                features['pitch_max'] = 0
            
            # Formants (ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ)
            formants = self._estimate_formants(y_trimmed, sr)
            features['formant_f1'] = formants[0] if len(formants) > 0 else 0
            features['formant_f2'] = formants[1] if len(formants) > 1 else 0
            
            # Jitter and Shimmer (ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ø·)
            features['jitter'] = self._calculate_jitter(pitch_values)
            features['shimmer'] = self._calculate_shimmer(y_trimmed)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© ÙˆØ§Ø­Ø¯Ø©
            feature_vector = np.concatenate([
                features['mfcc_mean'], features['mfcc_std'], features['mfcc_delta'],
                features['chroma_mean'], features['chroma_std'],
                [features['spectral_centroid_mean'], features['spectral_centroid_std']],
                [features['spectral_rolloff_mean']],
                [features['zcr_mean'], features['zcr_std']],
                [features['pitch_mean'], features['pitch_std'], 
                 features['pitch_min'], features['pitch_max']],
                [features['formant_f1'], features['formant_f2']],
                [features['jitter'], features['shimmer']]
            ])
            
            return feature_vector, features
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ: {e}")
            return None, None
    
    def _estimate_formants(self, y, sr, n_formants=2):
        """ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Formants)"""
        try:
            # Ø­Ø³Ø§Ø¨ LPC
            from scipy.signal import lfilter
            
            # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø§ÙØ°Ø© Ù‡Ø§Ù…ÙŠÙ†Øº
            windowed = y * np.hamming(len(y))
            
            # LPC analysis
            lpc_order = int(2 + sr / 1000)
            lpc_coeffs = librosa.lpc(windowed, order=lpc_order)
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø°ÙˆØ±
            roots = np.roots(lpc_coeffs)
            roots = roots[np.imag(roots) >= 0]
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ±Ø¯Ø¯Ø§Øª
            formants = []
            for root in roots:
                if np.abs(root) < 1:
                    freq = np.angle(root) * sr / (2 * np.pi)
                    if 100 < freq < sr/2:  # Ù†Ø·Ø§Ù‚ Ù…Ø¹Ù‚ÙˆÙ„ Ù„Ù„Ù€ formants
                        formants.append(freq)
            
            formants.sort()
            return formants[:n_formants]
            
        except Exception:
            return [0, 0]
    
    def _calculate_jitter(self, pitch_values):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Jitter (ØªØ°Ø¨Ø°Ø¨ Ø§Ù„ØµÙˆØª)"""
        if len(pitch_values) < 2:
            return 0
        
        differences = np.diff(pitch_values)
        mean_diff = np.mean(np.abs(differences))
        mean_pitch = np.mean(pitch_values)
        
        return mean_diff / mean_pitch if mean_pitch > 0 else 0
    
    def _calculate_shimmer(self, y):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Shimmer (ØªØ°Ø¨Ø°Ø¨ Ø§Ù„Ø·Ø§Ù‚Ø©)"""
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø¥Ø·Ø§Ø±Ø§Øª
        frame_length = 1024
        hop_length = 512
        
        frames = librosa.util.frame(y, frame_length=frame_length, 
                                  hop_length=hop_length, axis=0)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø·Ø§Ù‚Ø© Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø±
        energies = np.sum(frames**2, axis=1)
        
        if len(energies) < 2:
            return 0
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±ÙˆÙ‚
        differences = np.diff(energies)
        mean_diff = np.mean(np.abs(differences))
        mean_energy = np.mean(energies)
        
        return mean_diff / mean_energy if mean_energy > 0 else 0
    
    def create_voice_profile(self, audio_files, speaker_name, speaker_id=None):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ø¬Ø¯ÙŠØ¯"""
        
        if speaker_id is None:
            speaker_id = hashlib.md5(speaker_name.encode()).hexdigest()[:8]
        
        print(f"ğŸ‘¤ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ù„Ù€: {speaker_name}")
        
        all_features = []
        valid_files = 0
        
        for audio_file in audio_files:
            features, detailed_features = self.extract_voice_features(audio_file)
            if features is not None:
                all_features.append(features)
                valid_files += 1
        
        if valid_files < 1:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© ØµØ§Ù„Ø­Ø©")
            return False
        
        # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ GMM Ù„Ù„Ù…ØªØ­Ø¯Ø«
        features_matrix = np.array(all_features)
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        normalized_features = self.scaler.fit_transform(features_matrix)
        
        # ØªØ¯Ø±ÙŠØ¨ GMM
        gmm_model = GaussianMixture(
            n_components=min(self.n_components, len(all_features)),
            covariance_type='diag',
            random_state=42
        )
        gmm_model.fit(normalized_features)
        
        # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®ØµØ§Ø¦Øµ
        mean_features = np.mean(features_matrix, axis=0)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        voice_signature = {
            'gmm_model': gmm_model,
            'scaler': self.scaler,
            'mean_features': mean_features,
            'feature_stats': {
                'mean': np.mean(features_matrix, axis=0),
                'std': np.std(features_matrix, axis=0),
                'min': np.min(features_matrix, axis=0),
                'max': np.max(features_matrix, axis=0)
            }
        }
        
        # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._save_voice_profile(speaker_id, speaker_name, voice_signature, valid_files)
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.voice_profiles[speaker_id] = voice_signature
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø¨Ù†Ø¬Ø§Ø­ ({valid_files} Ù…Ù„ÙØ§Øª)")
        return True
    
    def _save_voice_profile(self, speaker_id, speaker_name, voice_signature, recordings_count):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        signature_blob = pickle.dumps(voice_signature)
        features_json = json.dumps({
            'mean_features': voice_signature['mean_features'].tolist(),
            'feature_stats': {
                key: value.tolist() for key, value in voice_signature['feature_stats'].items()
            }
        })
        
        current_time = datetime.now().isoformat()
        
        cursor.execute('''
            INSERT OR REPLACE INTO voice_profiles 
            (speaker_id, speaker_name, voice_signature, features_json, 
             recordings_count, created_date, last_updated, confidence_score)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (speaker_id, speaker_name, signature_blob, features_json,
              recordings_count, current_time, current_time, 0.95))
        
        conn.commit()
        conn.close()
    
    def identify_speaker(self, audio_path, threshold=0.7):
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ­Ø¯Ø« Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ"""
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ
        features, detailed_features = self.extract_voice_features(audio_path)
        if features is None:
            return None, 0
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
        self._load_voice_profiles()
        
        if not self.voice_profiles:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù…Ø­ÙÙˆØ¸Ø©")
            return None, 0
        
        best_match = None
        best_score = 0
        scores = {}
        
        print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚...")
        
        for speaker_id, profile in self.voice_profiles.items():
            try:
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø®ØµØ§Ø¦Øµ
                normalized_features = profile['scaler'].transform([features])
                
                # Ø­Ø³Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© GMM
                log_likelihood = profile['gmm_model'].score(normalized_features)
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„ÙƒÙˆØ³ÙŠÙ†ÙŠØ©
                cosine_sim = 1 - cosine(features, profile['mean_features'])
                
                # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
                combined_score = (log_likelihood / 10) + cosine_sim
                scores[speaker_id] = combined_score
                
                if combined_score > best_score:
                    best_score = combined_score
                    best_match = speaker_id
                    
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© {speaker_id}: {e}")
                continue
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
        confidence = min(max(best_score, 0), 1)
        
        if confidence >= threshold:
            speaker_name = self._get_speaker_name(best_match)
            print(f"âœ… ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰: {speaker_name} (Ø«Ù‚Ø©: {confidence:.2%})")
            
            # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø©
            self._save_session(best_match, audio_path, confidence, detailed_features)
            
            return {
                'speaker_id': best_match,
                'speaker_name': speaker_name,
                'confidence': confidence,
                'all_scores': scores
            }, confidence
        else:
            print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ­Ø¯Ø« (Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©: {confidence:.2%})")
            return None, confidence
    
    def _load_voice_profiles(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if self.voice_profiles:  # Ù…ÙØ­Ù…Ù„ Ù…Ø³Ø¨Ù‚Ø§Ù‹
            return
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT speaker_id, voice_signature FROM voice_profiles')
        rows = cursor.fetchall()
        
        for speaker_id, signature_blob in rows:
            try:
                voice_signature = pickle.loads(signature_blob)
                self.voice_profiles[speaker_id] = voice_signature
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù {speaker_id}: {e}")
        
        conn.close()
        print(f"ğŸ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.voice_profiles)} Ù…Ù„Ù ØµÙˆØªÙŠ")
    
    def _get_speaker_name(self, speaker_id):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù…ØªØ­Ø¯Ø«"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT speaker_name FROM voice_profiles WHERE speaker_id = ?', 
                      (speaker_id,))
        result = cursor.fetchone()
        conn.close()
        
        return result[0] if result else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    
    def _save_session(self, speaker_id, audio_path, confidence, features):
        """Ø­ÙØ¸ Ø¬Ù„Ø³Ø© Ø§Ù„ØªØ¹Ø±Ù"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        session_id = hashlib.md5(f"{speaker_id}_{datetime.now()}".encode()).hexdigest()[:12]
        
        cursor.execute('''
            INSERT INTO voice_sessions 
            (session_id, speaker_id, audio_path, recognition_confidence, 
             timestamp, features_extracted)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (session_id, speaker_id, audio_path, confidence,
              datetime.now().isoformat(), json.dumps(features)))
        
        conn.commit()
        conn.close()
    
    def detect_voice_spoofing(self, audio_path):
        """ÙƒØ´Ù Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…Ø²ÙŠÙØ© ÙˆØ§Ù„Ù…ØµØ·Ù†Ø¹Ø©"""
        
        features, detailed = self.extract_voice_features(audio_path)
        if features is None:
            return {'is_spoofed': True, 'confidence': 0, 'reason': 'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª'}
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø²ÙŠÙ
        spoofing_indicators = {
            'pitch_variance_low': detailed['pitch_std'] < 10,
            'unnatural_formants': detailed['formant_f1'] == 0 or detailed['formant_f2'] == 0,
            'low_jitter': detailed['jitter'] < 0.001,
            'low_shimmer': detailed['shimmer'] < 0.001,
            'spectral_anomaly': detailed['spectral_centroid_std'] < 100
        }
        
        # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
        positive_indicators = sum(spoofing_indicators.values())
        total_indicators = len(spoofing_indicators)
        
        spoofing_score = positive_indicators / total_indicators
        is_spoofed = spoofing_score >= self.deepfake_threshold
        
        return {
            'is_spoofed': is_spoofed,
            'confidence': spoofing_score,
            'indicators': spoofing_indicators,
            'recommendation': 'ØµÙˆØª Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡' if is_spoofed else 'ØµÙˆØª Ø·Ø¨ÙŠØ¹ÙŠ'
        }
    
    def get_voice_statistics(self):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
        cursor.execute('SELECT COUNT(*) FROM voice_profiles')
        profiles_count = cursor.fetchone()[0]
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute('SELECT COUNT(*) FROM voice_sessions')
        sessions_count = cursor.fetchone()[0]
        
        # Ø£Ø­Ø¯Ø« Ù†Ø´Ø§Ø·
        cursor.execute('''
            SELECT speaker_name, recognition_confidence, timestamp 
            FROM voice_sessions 
            JOIN voice_profiles ON voice_sessions.speaker_id = voice_profiles.speaker_id 
            ORDER BY timestamp DESC LIMIT 5
        ''')
        recent_activity = cursor.fetchall()
        
        conn.close()
        
        return {
            'total_profiles': profiles_count,
            'total_sessions': sessions_count,
            'recent_activity': recent_activity,
            'system_status': 'Ù†Ø´Ø·' if profiles_count > 0 else 'ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'
        }
    
    def analyze_voice_characteristics(self, audio_path):
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª"""
        
        features, detailed = self.extract_voice_features(audio_path)
        if features is None:
            return None
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        analysis = {
            'basic_info': {
                'duration': f"{librosa.get_duration(filename=audio_path):.2f} Ø«Ø§Ù†ÙŠØ©",
                'sample_rate': f"{self.sample_rate} Hz"
            },
            'pitch_analysis': {
                'average_pitch': f"{detailed['pitch_mean']:.1f} Hz",
                'pitch_range': f"{detailed['pitch_max'] - detailed['pitch_min']:.1f} Hz",
                'pitch_stability': 'Ù…Ø³ØªÙ‚Ø±' if detailed['pitch_std'] < 20 else 'Ù…ØªØ°Ø¨Ø°Ø¨'
            },
            'voice_quality': {
                'jitter': f"{detailed['jitter']:.4f}",
                'shimmer': f"{detailed['shimmer']:.4f}",
                'voice_quality': 'Ù…Ù…ØªØ§Ø²' if detailed['jitter'] < 0.01 and detailed['shimmer'] < 0.1 else 'Ø¬ÙŠØ¯'
            },
            'spectral_features': {
                'brightness': f"{detailed['spectral_centroid_mean']:.0f} Hz",
                'voice_richness': 'ØºÙ†ÙŠ' if detailed['spectral_rolloff_mean'] > 3000 else 'Ø¹Ø§Ø¯ÙŠ'
            },
            'speaker_characteristics': {
                'gender_estimate': 'Ø£Ù†Ø«Ù‰' if detailed['pitch_mean'] > 180 else 'Ø°ÙƒØ±',
                'age_estimate': self._estimate_age(detailed),
                'voice_type': self._classify_voice_type(detailed)
            }
        }
        
        return analysis
    
    def _estimate_age(self, features):
        """ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ù…Ø± Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ"""
        # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ø¨Ø³Ø·Ø© Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ù…Ø±
        pitch_mean = features['pitch_mean']
        jitter = features['jitter']
        shimmer = features['shimmer']
        
        if pitch_mean > 200 and jitter < 0.005:
            return "Ø´Ø§Ø¨ (18-30)"
        elif pitch_mean > 150 and jitter < 0.01:
            return "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø± (30-50)"
        elif jitter > 0.02 or shimmer > 0.15:
            return "ÙƒØ¨ÙŠØ± Ø§Ù„Ø³Ù† (50+)"
        else:
            return "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø±"
    
    def _classify_voice_type(self, features):
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØª"""
        pitch_mean = features['pitch_mean']
        
        if pitch_mean < 85:
            return "Ø¨Ø§Øµ"
        elif pitch_mean < 165:
            return "Ø¨Ø§Ø±ÙŠØªÙˆÙ†"
        elif pitch_mean < 220:
            return "ØªÙŠÙ†ÙˆØ±"
        elif pitch_mean < 330:
            return "Ø£Ù„ØªÙˆ"
        else:
            return "Ø³ÙˆØ¨Ø±Ø§Ù†Ùˆ"

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…
    voice_engine = VoiceBiometricsEngine()
    
    print("ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    print("=" * 50)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = voice_engine.get_voice_statistics()
    print(f"ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
    print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©: {stats['total_profiles']}")
    print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {stats['total_sessions']}")
    print(f"   - Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {stats['system_status']}")
