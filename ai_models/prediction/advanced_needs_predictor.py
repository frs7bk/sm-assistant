
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª
Advanced Needs Prediction Engine
"""

import asyncio
import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from pathlib import Path
import json
import sqlite3
from enum import Enum
import pickle
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

class NeedCategory(Enum):
    """ÙØ¦Ø§Øª Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª"""
    WORK = "work"
    HEALTH = "health"
    ENTERTAINMENT = "entertainment"
    SOCIAL = "social"
    LEARNING = "learning"
    SHOPPING = "shopping"
    TRAVEL = "travel"
    FINANCE = "finance"
    FOOD = "food"
    MAINTENANCE = "maintenance"

class Priority(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    URGENT = 4
    CRITICAL = 5

@dataclass
class PredictedNeed:
    """Ø­Ø§Ø¬Ø© Ù…ØªÙˆÙ‚Ø¹Ø©"""
    need_id: str
    category: NeedCategory
    description: str
    predicted_time: datetime
    confidence: float
    priority: Priority
    context: Dict[str, Any]
    suggested_actions: List[str]
    
@dataclass
class UserPattern:
    """Ù†Ù…Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    pattern_id: str
    name: str
    frequency: str  # daily, weekly, monthly
    typical_times: List[str]
    conditions: Dict[str, Any]
    associated_needs: List[str]
    accuracy: float

class AdvancedNeedsPredictor:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.db_path = Path("data/needs_predictor.db")
        self.db_path.parent.mkdir(exist_ok=True)
        
        # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ©
        self.models = {
            "time_predictor": RandomForestRegressor(n_estimators=100),
            "category_classifier": GradientBoostingClassifier(n_estimators=100),
            "priority_predictor": RandomForestRegressor(n_estimators=50)
        }
        
        self.scalers = {
            "features": StandardScaler(),
            "time": StandardScaler()
        }
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        self.historical_needs: List[Dict[str, Any]] = []
        self.user_patterns: Dict[str, UserPattern] = {}
        
        # Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚
        self.current_context = {
            "day_of_week": datetime.now().weekday(),
            "hour": datetime.now().hour,
            "season": self._get_season(),
            "weather_influence": 0.5,  # Ù…Ø­Ø§ÙƒØ§Ø©
            "stress_level": 0.3,
            "energy_level": 0.7,
            "social_activity": 0.5
        }
        
        # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒÙŠØ©
        self.prediction_rules = {
            "morning_routine": {
                "time_range": (6, 10),
                "typical_needs": ["work", "health", "food"],
                "confidence_boost": 0.2
            },
            "lunch_time": {
                "time_range": (11, 14),
                "typical_needs": ["food", "social"],
                "confidence_boost": 0.3
            },
            "evening_wind_down": {
                "time_range": (18, 22),
                "typical_needs": ["entertainment", "social", "health"],
                "confidence_boost": 0.25
            },
            "weekend_pattern": {
                "days": [5, 6],  # Saturday, Sunday
                "typical_needs": ["entertainment", "social", "maintenance"],
                "confidence_boost": 0.15
            }
        }

    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤"""
        
        try:
            self.logger.info("ğŸ”® ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª...")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            await self._initialize_database()
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
            await self._load_historical_data()
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            await self._train_prediction_models()
            
            # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            await self._discover_user_patterns()
            
            self.logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤")
            
        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")

    async def _initialize_database(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS historical_needs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                category TEXT NOT NULL,
                description TEXT,
                fulfilled_time TEXT,
                priority INTEGER,
                context TEXT,
                outcome TEXT
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_patterns (
                pattern_id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                frequency TEXT,
                typical_times TEXT,
                conditions TEXT,
                associated_needs TEXT,
                accuracy REAL
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS predictions (
                prediction_id TEXT PRIMARY KEY,
                predicted_time TEXT NOT NULL,
                category TEXT NOT NULL,
                description TEXT,
                confidence REAL,
                priority INTEGER,
                status TEXT,
                actual_outcome TEXT
            )
        """)
        
        conn.commit()
        conn.close()

    async def _load_historical_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
            cursor.execute("SELECT * FROM historical_needs ORDER BY timestamp DESC LIMIT 1000")
            for row in cursor.fetchall():
                need_data = {
                    "id": row[0],
                    "timestamp": datetime.fromisoformat(row[1]),
                    "category": row[2],
                    "description": row[3],
                    "fulfilled_time": datetime.fromisoformat(row[4]) if row[4] else None,
                    "priority": row[5],
                    "context": json.loads(row[6]) if row[6] else {},
                    "outcome": row[7]
                }
                self.historical_needs.append(need_data)
            
            # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ©
            if not self.historical_needs:
                await self._generate_sample_data()
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©: {e}")

    async def _generate_sample_data(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
        
        sample_needs = [
            {"category": "work", "description": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª", "hour": 9, "priority": 3},
            {"category": "food", "description": "Ø·Ù„Ø¨ Ø§Ù„ØºØ¯Ø§Ø¡", "hour": 12, "priority": 4},
            {"category": "health", "description": "Ø´Ø±Ø¨ Ø§Ù„Ù…Ø§Ø¡", "hour": 14, "priority": 2},
            {"category": "entertainment", "description": "Ù…Ø´Ø§Ù‡Ø¯Ø© ÙÙŠØ¯ÙŠÙˆ", "hour": 19, "priority": 1},
            {"category": "social", "description": "Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø£ØµØ¯Ù‚Ø§Ø¡", "hour": 20, "priority": 2}
        ]
        
        base_date = datetime.now() - timedelta(days=30)
        
        for i in range(100):  # 100 Ø­Ø§Ø¬Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            for need in sample_needs:
                # Ø¥Ø¶Ø§ÙØ© ØªÙ†ÙˆÙŠØ¹ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
                date = base_date + timedelta(days=i//5, hours=need["hour"] + np.random.randint(-2, 3))
                
                need_data = {
                    "id": len(self.historical_needs) + 1,
                    "timestamp": date,
                    "category": need["category"],
                    "description": need["description"],
                    "fulfilled_time": date + timedelta(minutes=np.random.randint(5, 60)),
                    "priority": need["priority"],
                    "context": {
                        "day_of_week": date.weekday(),
                        "hour": date.hour,
                        "weather": np.random.choice(["sunny", "cloudy", "rainy"]),
                        "stress_level": np.random.uniform(0, 1)
                    },
                    "outcome": np.random.choice(["fulfilled", "postponed", "ignored"])
                }
                
                self.historical_needs.append(need_data)

    async def _train_prediction_models(self):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ©"""
        
        if len(self.historical_needs) < 50:
            self.logger.warning("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
            return
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨
            features, targets = await self._prepare_training_data()
            
            if len(features) == 0:
                return
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_time_train, y_time_test = train_test_split(
                features, targets["time"], test_size=0.2, random_state=42
            )
            
            _, _, y_cat_train, y_cat_test = train_test_split(
                features, targets["category"], test_size=0.2, random_state=42
            )
            
            _, _, y_priority_train, y_priority_test = train_test_split(
                features, targets["priority"], test_size=0.2, random_state=42
            )
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train_scaled = self.scalers["features"].fit_transform(X_train)
            X_test_scaled = self.scalers["features"].transform(X_test)
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            self.models["time_predictor"].fit(X_train_scaled, y_time_train)
            self.models["category_classifier"].fit(X_train_scaled, y_cat_train)
            self.models["priority_predictor"].fit(X_train_scaled, y_priority_train)
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
            time_score = self.models["time_predictor"].score(X_test_scaled, y_time_test)
            cat_score = self.models["category_classifier"].score(X_test_scaled, y_cat_test)
            priority_score = self.models["priority_predictor"].score(X_test_scaled, y_priority_test)
            
            self.logger.info(f"ğŸ“Š Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ - Ø§Ù„ÙˆÙ‚Øª: {time_score:.2f}, Ø§Ù„ÙØ¦Ø©: {cat_score:.2f}, Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: {priority_score:.2f}")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")

    async def _prepare_training_data(self) -> Tuple[List[List[float]], Dict[str, List]]:
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        
        features = []
        targets = {"time": [], "category": [], "priority": []}
        
        for need in self.historical_needs:
            if need["fulfilled_time"]:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                feature_vector = [
                    need["context"].get("day_of_week", 0),
                    need["context"].get("hour", 12),
                    need["context"].get("stress_level", 0.5),
                    need["priority"],
                    hash(need["category"]) % 100,  # ØªØ´ÙÙŠØ± Ø§Ù„ÙØ¦Ø©
                    len(need["description"]),
                    (need["fulfilled_time"] - need["timestamp"]).total_seconds() / 3600  # Ø§Ù„ÙˆÙ‚Øª Ù„Ù„ØªÙ†ÙÙŠØ° Ø¨Ø§Ù„Ø³Ø§Ø¹Ø§Øª
                ]
                
                features.append(feature_vector)
                
                # Ø§Ù„Ø£Ù‡Ø¯Ø§Ù
                time_to_fulfillment = (need["fulfilled_time"] - need["timestamp"]).total_seconds() / 3600
                targets["time"].append(time_to_fulfillment)
                targets["category"].append(need["category"])
                targets["priority"].append(need["priority"])
        
        return features, targets

    async def _discover_user_patterns(self):
        """Ø§ÙƒØªØ´Ø§Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        
        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            await self._analyze_temporal_patterns()
            
            # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¦Ø§Øª
            await self._analyze_category_patterns()
            
            # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³ÙŠØ§Ù‚
            await self._analyze_context_patterns()
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")

    async def _analyze_temporal_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ø§Ø¹Ø©
        hourly_data = {}
        for need in self.historical_needs:
            hour = need["timestamp"].hour
            category = need["category"]
            
            if hour not in hourly_data:
                hourly_data[hour] = {}
            
            if category not in hourly_data[hour]:
                hourly_data[hour][category] = 0
            
            hourly_data[hour][category] += 1
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        for hour, categories in hourly_data.items():
            dominant_category = max(categories, key=categories.get)
            frequency = categories[dominant_category]
            
            if frequency >= 3:  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„ØªÙƒØ±Ø§Ø±
                pattern = UserPattern(
                    pattern_id=f"hourly_{hour}_{dominant_category}",
                    name=f"Ù†Ù…Ø· Ø§Ù„Ø³Ø§Ø¹Ø© {hour} - {dominant_category}",
                    frequency="daily",
                    typical_times=[str(hour)],
                    conditions={"hour": hour},
                    associated_needs=[dominant_category],
                    accuracy=min(frequency / 10, 1.0)
                )
                
                self.user_patterns[pattern.pattern_id] = pattern

    async def _analyze_category_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¦Ø§Øª"""
        
        # ØªØ­Ù„ÙŠÙ„ ØªØ³Ù„Ø³Ù„ Ø§Ù„ÙØ¦Ø§Øª
        category_sequences = []
        
        sorted_needs = sorted(self.historical_needs, key=lambda x: x["timestamp"])
        
        for i in range(len(sorted_needs) - 2):
            sequence = [
                sorted_needs[i]["category"],
                sorted_needs[i+1]["category"],
                sorted_needs[i+2]["category"]
            ]
            category_sequences.append(sequence)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
        sequence_counts = {}
        for seq in category_sequences:
            seq_str = "->".join(seq)
            sequence_counts[seq_str] = sequence_counts.get(seq_str, 0) + 1
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ù†Ù…Ø§Ø· Ù„Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        for sequence, count in sequence_counts.items():
            if count >= 3:
                pattern = UserPattern(
                    pattern_id=f"sequence_{hash(sequence) % 1000}",
                    name=f"Ù†Ù…Ø· Ø§Ù„ØªØ³Ù„Ø³Ù„: {sequence}",
                    frequency="variable",
                    typical_times=[],
                    conditions={"sequence": sequence.split("->")},
                    associated_needs=sequence.split("->"),
                    accuracy=min(count / 10, 1.0)
                )
                
                self.user_patterns[pattern.pattern_id] = pattern

    async def _analyze_context_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³ÙŠØ§Ù‚"""
        
        # ØªØ­Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø·Ù‚Ø³
        weather_influence = {}
        for need in self.historical_needs:
            weather = need["context"].get("weather", "unknown")
            category = need["category"]
            
            if weather not in weather_influence:
                weather_influence[weather] = {}
            
            if category not in weather_influence[weather]:
                weather_influence[weather][category] = 0
            
            weather_influence[weather][category] += 1
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø·Ù‚Ø³
        for weather, categories in weather_influence.items():
            if weather != "unknown" and len(categories) > 0:
                dominant_category = max(categories, key=categories.get)
                
                pattern = UserPattern(
                    pattern_id=f"weather_{weather}_{dominant_category}",
                    name=f"Ù†Ù…Ø· Ø§Ù„Ø·Ù‚Ø³ {weather} - {dominant_category}",
                    frequency="conditional",
                    typical_times=[],
                    conditions={"weather": weather},
                    associated_needs=[dominant_category],
                    accuracy=0.6
                )
                
                self.user_patterns[pattern.pattern_id] = pattern

    def _get_season(self) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        
        month = datetime.now().month
        if month in [12, 1, 2]:
            return "winter"
        elif month in [3, 4, 5]:
            return "spring"
        elif month in [6, 7, 8]:
            return "summer"
        else:
            return "autumn"

    async def predict_upcoming_needs(
        self,
        time_horizon: int = 24,  # Ø³Ø§Ø¹Ø§Øª
        max_predictions: int = 10
    ) -> List[PredictedNeed]:
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©"""
        
        try:
            predictions = []
            current_time = datetime.now()
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
            ml_predictions = await self._predict_with_ml_models(time_horizon)
            predictions.extend(ml_predictions)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
            pattern_predictions = await self._predict_with_patterns(time_horizon)
            predictions.extend(pattern_predictions)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠØ©
            rule_predictions = await self._predict_with_rules(time_horizon)
            predictions.extend(rule_predictions)
            
            # ØªØ±ØªÙŠØ¨ ÙˆØªØµÙÙŠØ© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            predictions = sorted(predictions, key=lambda x: (x.predicted_time, -x.confidence))
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯
            unique_predictions = []
            seen_descriptions = set()
            
            for pred in predictions:
                if pred.description not in seen_descriptions and len(unique_predictions) < max_predictions:
                    unique_predictions.append(pred)
                    seen_descriptions.add(pred.description)
            
            return unique_predictions
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª: {e}")
            return []

    async def _predict_with_ml_models(self, time_horizon: int) -> List[PredictedNeed]:
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        
        predictions = []
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø§Ø· Ø²Ù…Ù†ÙŠØ© Ù„Ù„ØªÙ†Ø¨Ø¤
            time_points = []
            for hour_offset in range(1, time_horizon + 1):
                future_time = datetime.now() + timedelta(hours=hour_offset)
                time_points.append(future_time)
            
            for future_time in time_points:
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ
                context_features = [
                    future_time.weekday(),
                    future_time.hour,
                    self.current_context["stress_level"],
                    3,  # Ø£ÙˆÙ„ÙˆÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                    50,  # ÙØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ø´ÙØ±Ø©
                    10,  # Ø·ÙˆÙ„ ÙˆØµÙ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                    1.0  # ÙˆÙ‚Øª Ù„Ù„ØªÙ†ÙÙŠØ° Ø§ÙØªØ±Ø§Ø¶ÙŠ
                ]
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ·Ø¨ÙŠØ¹
                features_scaled = self.scalers["features"].transform([context_features])
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                if hasattr(self.models["time_predictor"], "predict"):
                    time_pred = self.models["time_predictor"].predict(features_scaled)[0]
                    category_pred = self.models["category_classifier"].predict(features_scaled)[0]
                    priority_pred = self.models["priority_predictor"].predict(features_scaled)[0]
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
                    confidence = self._calculate_ml_confidence(future_time, context_features)
                    
                    if confidence > 0.3:  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø«Ù‚Ø©
                        prediction = PredictedNeed(
                            need_id=f"ml_{future_time.isoformat()}_{category_pred}",
                            category=NeedCategory(category_pred) if category_pred in [c.value for c in NeedCategory] else NeedCategory.WORK,
                            description=self._generate_need_description(category_pred, future_time),
                            predicted_time=future_time,
                            confidence=confidence,
                            priority=Priority(max(1, min(5, int(priority_pred)))),
                            context={"source": "ml_model", "hour": future_time.hour},
                            suggested_actions=self._generate_suggested_actions(category_pred)
                        )
                        
                        predictions.append(prediction)
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
        
        return predictions

    async def _predict_with_patterns(self, time_horizon: int) -> List[PredictedNeed]:
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©"""
        
        predictions = []
        
        for pattern in self.user_patterns.values():
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø±ÙˆØ· Ø§Ù„Ù†Ù…Ø·
                if await self._pattern_conditions_met(pattern):
                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
                    predicted_time = await self._calculate_pattern_time(pattern)
                    
                    if predicted_time and predicted_time <= datetime.now() + timedelta(hours=time_horizon):
                        for need_category in pattern.associated_needs:
                            prediction = PredictedNeed(
                                need_id=f"pattern_{pattern.pattern_id}_{need_category}",
                                category=NeedCategory(need_category) if need_category in [c.value for c in NeedCategory] else NeedCategory.WORK,
                                description=self._generate_need_description(need_category, predicted_time),
                                predicted_time=predicted_time,
                                confidence=pattern.accuracy * 0.8,  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹
                                priority=Priority.MEDIUM,
                                context={"source": "pattern", "pattern_id": pattern.pattern_id},
                                suggested_actions=self._generate_suggested_actions(need_category)
                            )
                            
                            predictions.append(prediction)
            
            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ù…Ø· {pattern.pattern_id}: {e}")
        
        return predictions

    async def _predict_with_rules(self, time_horizon: int) -> List[PredictedNeed]:
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠØ©"""
        
        predictions = []
        
        current_time = datetime.now()
        
        for rule_name, rule_config in self.prediction_rules.items():
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø±ÙˆØ· Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
                if await self._rule_conditions_met(rule_name, rule_config):
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
                    predicted_time = await self._calculate_rule_time(rule_config)
                    
                    if predicted_time and predicted_time <= current_time + timedelta(hours=time_horizon):
                        for need_category in rule_config["typical_needs"]:
                            confidence = 0.6 + rule_config.get("confidence_boost", 0)
                            
                            prediction = PredictedNeed(
                                need_id=f"rule_{rule_name}_{need_category}",
                                category=NeedCategory(need_category) if need_category in [c.value for c in NeedCategory] else NeedCategory.WORK,
                                description=self._generate_need_description(need_category, predicted_time),
                                predicted_time=predicted_time,
                                confidence=min(confidence, 1.0),
                                priority=Priority.MEDIUM,
                                context={"source": "rule", "rule_name": rule_name},
                                suggested_actions=self._generate_suggested_actions(need_category)
                            )
                            
                            predictions.append(prediction)
            
            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© {rule_name}: {e}")
        
        return predictions

    def _calculate_ml_confidence(self, future_time: datetime, features: List[float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ù„Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        
        base_confidence = 0.5
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø«Ù‚Ø© Ù„Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ù…Ø£Ù„ÙˆÙØ©
        hour = future_time.hour
        if 9 <= hour <= 17:  # Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„
            base_confidence += 0.2
        elif 18 <= hour <= 22:  # Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¡
            base_confidence += 0.1
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù„Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¨Ø¹ÙŠØ¯Ø©
        hours_ahead = (future_time - datetime.now()).total_seconds() / 3600
        if hours_ahead > 12:
            base_confidence -= 0.2
        
        return max(0.1, min(1.0, base_confidence))

    async def _pattern_conditions_met(self, pattern: UserPattern) -> bool:
        """ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„Ù†Ù…Ø·"""
        
        conditions = pattern.conditions
        current_time = datetime.now()
        
        # ÙØ­Øµ Ø§Ù„Ø³Ø§Ø¹Ø©
        if "hour" in conditions:
            return abs(current_time.hour - conditions["hour"]) <= 1
        
        # ÙØ­Øµ Ø§Ù„Ø·Ù‚Ø³
        if "weather" in conditions:
            # Ù…Ø­Ø§ÙƒØ§Ø© - ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù‚Ø³ Ù…Ù† API
            return True
        
        # ÙØ­Øµ Ø§Ù„ØªØ³Ù„Ø³Ù„
        if "sequence" in conditions:
            # ÙØ­Øµ Ø¢Ø®Ø± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª
            recent_needs = [need["category"] for need in self.historical_needs[-3:]]
            expected_sequence = conditions["sequence"][:-1]  # ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ø¯Ø§ Ø§Ù„Ø£Ø®ÙŠØ±
            return recent_needs == expected_sequence
        
        return True

    async def _calculate_pattern_time(self, pattern: UserPattern) -> Optional[datetime]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„Ù†Ù…Ø·"""
        
        current_time = datetime.now()
        
        if pattern.frequency == "daily" and pattern.typical_times:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª Ù…Ù†Ø§Ø³Ø¨
            target_hour = int(pattern.typical_times[0])
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆÙ‚Øª Ù‚Ø¯ Ù…Ø¶Ù‰ Ø§Ù„ÙŠÙˆÙ…ØŒ Ø§Ø®ØªØ± Ø§Ù„ØºØ¯
            if current_time.hour >= target_hour:
                target_time = current_time.replace(hour=target_hour, minute=0, second=0, microsecond=0) + timedelta(days=1)
            else:
                target_time = current_time.replace(hour=target_hour, minute=0, second=0, microsecond=0)
            
            return target_time
        
        return None

    async def _rule_conditions_met(self, rule_name: str, rule_config: Dict[str, Any]) -> bool:
        """ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©"""
        
        current_time = datetime.now()
        
        # ÙØ­Øµ Ù†Ø·Ø§Ù‚ Ø§Ù„ÙˆÙ‚Øª
        if "time_range" in rule_config:
            start_hour, end_hour = rule_config["time_range"]
            if not (start_hour <= current_time.hour <= end_hour):
                return False
        
        # ÙØ­Øµ Ø£ÙŠØ§Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
        if "days" in rule_config:
            if current_time.weekday() not in rule_config["days"]:
                return False
        
        return True

    async def _calculate_rule_time(self, rule_config: Dict[str, Any]) -> Optional[datetime]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„Ù‚Ø§Ø¹Ø¯Ø©"""
        
        current_time = datetime.now()
        
        if "time_range" in rule_config:
            start_hour, end_hour = rule_config["time_range"]
            
            # Ø§Ø®ØªÙŠØ§Ø± ÙˆÙ‚Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠ ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚
            if current_time.hour < start_hour:
                target_hour = start_hour
                target_time = current_time.replace(hour=target_hour, minute=0, second=0, microsecond=0)
            elif current_time.hour > end_hour:
                target_hour = start_hour
                target_time = current_time.replace(hour=target_hour, minute=0, second=0, microsecond=0) + timedelta(days=1)
            else:
                # Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚
                target_time = current_time + timedelta(minutes=np.random.randint(15, 120))
            
            return target_time
        
        return current_time + timedelta(hours=1)

    def _generate_need_description(self, category: str, predicted_time: datetime) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ù„Ù„Ø­Ø§Ø¬Ø©"""
        
        descriptions = {
            "work": [
                "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª",
                "Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©",
                "Ø­Ø¶ÙˆØ± Ø§Ø¬ØªÙ…Ø§Ø¹",
                "ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±"
            ],
            "food": [
                "ØªÙ†Ø§ÙˆÙ„ ÙˆØ¬Ø¨Ø©",
                "Ø´Ø±Ø¨ Ø§Ù„Ù…Ø§Ø¡",
                "Ø·Ù„Ø¨ Ø§Ù„Ø·Ø¹Ø§Ù…",
                "ØªØ­Ø¶ÙŠØ± ÙˆØ¬Ø¨Ø© Ø®ÙÙŠÙØ©"
            ],
            "health": [
                "Ø£Ø®Ø° Ø§Ø³ØªØ±Ø§Ø­Ø©",
                "Ù…Ù…Ø§Ø±Ø³Ø© Ø§Ù„ØªÙ…Ø§Ø±ÙŠÙ†",
                "ÙØ­Øµ Ø§Ù„ØµØ­Ø©",
                "Ø§Ù„Ø§Ø³ØªØ±Ø®Ø§Ø¡"
            ],
            "entertainment": [
                "Ù…Ø´Ø§Ù‡Ø¯Ø© ÙÙŠØ¯ÙŠÙˆ",
                "Ù‚Ø±Ø§Ø¡Ø© ÙƒØªØ§Ø¨",
                "Ù„Ø¹Ø¨ Ù„Ø¹Ø¨Ø©",
                "Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰"
            ],
            "social": [
                "Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø£ØµØ¯Ù‚Ø§Ø¡",
                "Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙÙŠ Ù†Ø´Ø§Ø· Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ",
                "Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©",
                "Ø¥Ø¬Ø±Ø§Ø¡ Ù…ÙƒØ§Ù„Ù…Ø©"
            ]
        }
        
        category_descriptions = descriptions.get(category, ["Ù†Ø´Ø§Ø· Ø¹Ø§Ù…"])
        base_description = np.random.choice(category_descriptions)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ
        hour = predicted_time.hour
        if 6 <= hour <= 10:
            time_context = "ØµØ¨Ø§Ø­ÙŠØ©"
        elif 11 <= hour <= 14:
            time_context = "Ø¸Ù‡Ø±"
        elif 15 <= hour <= 18:
            time_context = "Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±"
        else:
            time_context = "Ù…Ø³Ø§Ø¦ÙŠØ©"
        
        return f"{base_description} ({time_context})"

    def _generate_suggested_actions(self, category: str) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"""
        
        actions = {
            "work": [
                "ÙØªØ­ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ",
                "Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‡Ø§Ù…",
                "Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¹Ù…Ù„"
            ],
            "food": [
                "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø·Ø¨Ø®",
                "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ù‚Ø±ÙŠØ¨Ø©",
                "Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙˆØ¬Ø¨Ø§Øª"
            ],
            "health": [
                "Ø¶Ø¨Ø· ØªØ°ÙƒÙŠØ± Ù„Ù„Ø±Ø§Ø­Ø©",
                "ÙØªØ­ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù„ÙŠØ§Ù‚Ø©",
                "ØªØ­Ø¶ÙŠØ± Ù…ÙƒØ§Ù† Ù„Ù„ØªÙ…Ø§Ø±ÙŠÙ†"
            ],
            "entertainment": [
                "ÙØªØ­ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ±ÙÙŠÙ‡",
                "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ Ø¬Ø¯ÙŠØ¯",
                "ØªØ¬Ù‡ÙŠØ² Ù…ÙƒØ§Ù† Ù…Ø±ÙŠØ­"
            ],
            "social": [
                "ÙØªØ­ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø§Ø³Ù„Ø©",
                "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬Ù‡Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„",
                "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©"
            ]
        }
        
        return actions.get(category, ["Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„Ù†Ø´Ø§Ø·"])

    async def update_context(self, new_context: Dict[str, Any]):
        """ØªØ­Ø¯ÙŠØ« Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        
        self.current_context.update(new_context)
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØºÙŠÙŠØ± Ù…Ù‡Ù…
        significant_changes = ["stress_level", "energy_level", "location"]
        if any(key in new_context for key in significant_changes):
            self.logger.info("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØºÙŠÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚")

    async def record_need_fulfillment(
        self,
        need_description: str,
        category: str,
        fulfilled: bool,
        notes: str = ""
    ):
        """ØªØ³Ø¬ÙŠÙ„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø§Ø¬Ø©"""
        
        try:
            need_data = {
                "timestamp": datetime.now(),
                "category": category,
                "description": need_description,
                "fulfilled_time": datetime.now() if fulfilled else None,
                "priority": 3,
                "context": self.current_context.copy(),
                "outcome": "fulfilled" if fulfilled else "unfulfilled"
            }
            
            self.historical_needs.append(need_data)
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            await self._save_need_to_db(need_data)
            
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ†Ø§ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©
            if len(self.historical_needs) % 50 == 0:
                await self._train_prediction_models()
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø§Ø¬Ø©: {e}")

    async def _save_need_to_db(self, need_data: Dict[str, Any]):
        """Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ø¬Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO historical_needs 
            (timestamp, category, description, fulfilled_time, priority, context, outcome)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            need_data["timestamp"].isoformat(),
            need_data["category"],
            need_data["description"],
            need_data["fulfilled_time"].isoformat() if need_data["fulfilled_time"] else None,
            need_data["priority"],
            json.dumps(need_data["context"]),
            need_data["outcome"]
        ))
        
        conn.commit()
        conn.close()

    async def get_prediction_analytics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤"""
        
        try:
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            total_needs = len(self.historical_needs)
            fulfilled_needs = len([n for n in self.historical_needs if n["outcome"] == "fulfilled"])
            fulfillment_rate = fulfilled_needs / total_needs if total_needs > 0 else 0
            
            # ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            pattern_accuracy = {}
            for pattern_id, pattern in self.user_patterns.items():
                pattern_accuracy[pattern_id] = {
                    "name": pattern.name,
                    "accuracy": pattern.accuracy,
                    "frequency": pattern.frequency
                }
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            category_counts = {}
            for need in self.historical_needs:
                category = need["category"]
                category_counts[category] = category_counts.get(category, 0) + 1
            
            most_common_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹
            hourly_activity = {}
            for need in self.historical_needs:
                hour = need["timestamp"].hour
                hourly_activity[hour] = hourly_activity.get(hour, 0) + 1
            
            peak_hours = sorted(hourly_activity.items(), key=lambda x: x[1], reverse=True)[:3]
            
            return {
                "general_statistics": {
                    "total_needs": total_needs,
                    "fulfillment_rate": round(fulfillment_rate * 100, 1),
                    "active_patterns": len(self.user_patterns)
                },
                "pattern_analysis": pattern_accuracy,
                "category_analysis": {
                    "most_common": most_common_categories,
                    "distribution": category_counts
                },
                "temporal_analysis": {
                    "peak_hours": peak_hours,
                    "hourly_distribution": hourly_activity
                },
                "context_influence": {
                    "stress_correlation": self._calculate_stress_correlation(),
                    "day_of_week_preferences": self._calculate_day_preferences()
                },
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return {"error": str(e)}

    def _calculate_stress_correlation(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„ØªÙˆØªØ± ÙˆØ§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª"""
        
        stress_levels = []
        need_counts = []
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙˆØªØ±
        stress_groups = {}
        for need in self.historical_needs:
            stress = need["context"].get("stress_level", 0.5)
            stress_bucket = round(stress * 10) / 10  # ØªÙ‚Ø±ÙŠØ¨ Ù„Ø£Ù‚Ø±Ø¨ 0.1
            
            if stress_bucket not in stress_groups:
                stress_groups[stress_bucket] = 0
            stress_groups[stress_bucket] += 1
        
        for stress, count in stress_groups.items():
            stress_levels.append(stress)
            need_counts.append(count)
        
        if len(stress_levels) > 1:
            correlation = np.corrcoef(stress_levels, need_counts)[0, 1]
            return correlation if not np.isnan(correlation) else 0.0
        
        return 0.0

    def _calculate_day_preferences(self) -> Dict[str, int]:
        """Ø­Ø³Ø§Ø¨ ØªÙØ¶ÙŠÙ„Ø§Øª Ø£ÙŠØ§Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"""
        
        day_counts = {}
        day_names = ["Ø§Ù„Ø§Ø«Ù†ÙŠÙ†", "Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡", "Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡", "Ø§Ù„Ø®Ù…ÙŠØ³", "Ø§Ù„Ø¬Ù…Ø¹Ø©", "Ø§Ù„Ø³Ø¨Øª", "Ø§Ù„Ø£Ø­Ø¯"]
        
        for need in self.historical_needs:
            day = need["timestamp"].weekday()
            day_name = day_names[day]
            day_counts[day_name] = day_counts.get(day_name, 0) + 1
        
        return day_counts

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø¹Ø§Ù…
needs_predictor = AdvancedNeedsPredictor()

async def get_needs_predictor() -> AdvancedNeedsPredictor:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤"""
    return needs_predictor

if __name__ == "__main__":
    async def test_needs_predictor():
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤"""
        print("ğŸ”® Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª")
        print("=" * 50)
        
        predictor = await get_needs_predictor()
        await predictor.initialize()
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤
        print("\nğŸ” Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©...")
        predictions = await predictor.predict_upcoming_needs(time_horizon=12, max_predictions=5)
        
        for i, pred in enumerate(predictions, 1):
            print(f"\n{i}. {pred.description}")
            print(f"   ğŸ“… Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {pred.predicted_time.strftime('%H:%M')}")
            print(f"   ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: {pred.confidence:.1%}")
            print(f"   â­ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: {pred.priority.name}")
            print(f"   ğŸ’¡ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù…Ù‚ØªØ±Ø­Ø©: {', '.join(pred.suggested_actions[:2])}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± ØªØ³Ø¬ÙŠÙ„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø§Ø¬Ø©
        print("\nğŸ“ ØªØ³Ø¬ÙŠÙ„ ØªÙ†ÙÙŠØ° Ø­Ø§Ø¬Ø©...")
        await predictor.record_need_fulfillment(
            need_description="Ø´Ø±Ø¨ Ø§Ù„Ù…Ø§Ø¡",
            category="health",
            fulfilled=True,
            notes="ØªÙ… Ø§Ù„ØªÙ†ÙÙŠØ° ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø­Ø¯Ø¯"
        )
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤:")
        analytics = await predictor.get_prediction_analytics()
        stats = analytics["general_statistics"]
        print(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª: {stats['total_needs']}")
        print(f"âœ… Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°: {stats['fulfillment_rate']}%")
        print(f"ğŸ”„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø´Ø·Ø©: {stats['active_patterns']}")
        
        # Ø¹Ø±Ø¶ Ø£ÙƒØ«Ø± Ø§Ù„ÙØ¦Ø§Øª Ø´ÙŠÙˆØ¹Ø§Ù‹
        print(f"\nğŸ† Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹:")
        for category, count in analytics["category_analysis"]["most_common"][:3]:
            print(f"   â€¢ {category}: {count} Ù…Ø±Ø©")
    
    asyncio.run(test_needs_predictor())
