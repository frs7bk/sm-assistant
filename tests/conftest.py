
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§ª Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª pytest ÙˆØªØ±ÙƒÙŠØ¨Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
pytest Configuration and Fixtures
"""

import pytest
import asyncio
import tempfile
import shutil
import sys
import logging
from pathlib import Path
from unittest.mock import Mock, patch

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
logging.basicConfig(
    level=logging.WARNING,  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    format='%(levelname)s - %(name)s - %(message)s'
)

@pytest.fixture(scope="session")
def event_loop():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù„Ù‚Ø© Ø£Ø­Ø¯Ø§Ø« Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©"""
    loop = asyncio.new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def temp_directory():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    temp_dir = tempfile.mkdtemp()
    yield Path(temp_dir)
    shutil.rmtree(temp_dir, ignore_errors=True)

@pytest.fixture
def mock_config():
    """Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙ‡ÙŠØ¦Ø© ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    config = Mock()
    config.ai_models = Mock()
    config.ai_models.device = "cpu"
    config.ai_models.max_batch_size = 1
    config.ai_models.use_gpu = False
    
    config.logging = Mock()
    config.logging.level = "WARNING"
    
    config.database = Mock()
    config.database.path = ":memory:"
    
    return config

@pytest.fixture
def mock_logger():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø¬Ù„ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    logger = Mock()
    logger.info = Mock()
    logger.warning = Mock()
    logger.error = Mock()
    logger.debug = Mock()
    return logger

@pytest.fixture
def sample_user_data():
    """Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    return {
        "user_id": "test_user_123",
        "preferences": {
            "language": "ar",
            "theme": "light",
            "voice_enabled": False
        },
        "interaction_history": [
            {
                "timestamp": "2025-01-26T20:00:00",
                "input": "Ù…Ø±Ø­Ø¨Ø§Ù‹",
                "output": "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹",
                "sentiment": "positive"
            },
            {
                "timestamp": "2025-01-26T20:01:00", 
                "input": "ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠØŸ",
                "output": "ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª",
                "sentiment": "neutral"
            }
        ],
        "learned_patterns": {
            "common_topics": ["ØªÙ‚Ù†ÙŠØ©", "ØªØ¹Ù„ÙŠÙ…", "Ø¹Ù…Ù„"],
            "preferred_response_style": "formal",
            "typical_session_length": 15
        }
    }

@pytest.fixture
def sample_ai_models():
    """Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    models = {}
    
    # Ù†Ù…ÙˆØ°Ø¬ NLP ÙˆÙ‡Ù…ÙŠ
    nlp_model = Mock()
    nlp_model.analyze = Mock(return_value={
        "sentiment": "positive",
        "confidence": 0.85,
        "entities": []
    })
    models["nlp"] = nlp_model
    
    # Ù†Ù…ÙˆØ°Ø¬ ØªÙˆÙ„ÙŠØ¯ ÙˆÙ‡Ù…ÙŠ
    generation_model = Mock()
    generation_model.generate = Mock(return_value={
        "text": "Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆÙ„Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
        "confidence": 0.90
    })
    models["generation"] = generation_model
    
    # Ù†Ù…ÙˆØ°Ø¬ Ø±Ø¤ÙŠØ© ÙˆÙ‡Ù…ÙŠ
    vision_model = Mock()
    vision_model.analyze_image = Mock(return_value={
        "objects": ["Ø´Ø®Øµ", "Ø³ÙŠØ§Ø±Ø©"],
        "scene": "Ø´Ø§Ø±Ø¹",
        "confidence": 0.75
    })
    models["vision"] = vision_model
    
    return models

@pytest.fixture
def mock_openai_client():
    """Ø¹Ù…ÙŠÙ„ OpenAI ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    with patch('openai.OpenAI') as mock_client:
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª ÙˆÙ‡Ù…ÙŠØ©
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message = Mock()
        mock_response.choices[0].message.content = "Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT ÙˆÙ‡Ù…ÙŠØ©"
        
        mock_client.return_value.chat.completions.create.return_value = mock_response
        yield mock_client.return_value

@pytest.fixture
def test_database_path(temp_directory):
    """Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    db_path = temp_directory / "test_database.db"
    yield str(db_path)

@pytest.fixture(autouse=True)
def setup_test_environment(monkeypatch, temp_directory):
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    # ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    monkeypatch.setenv("TESTING", "true")
    monkeypatch.setenv("LOG_LEVEL", "WARNING")
    monkeypatch.setenv("AI_DEVICE", "cpu")
    monkeypatch.setenv("USE_GPU", "false")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    test_data_dir = temp_directory / "data"
    test_data_dir.mkdir(exist_ok=True)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª ÙØ±Ø¹ÙŠØ©
    for subdir in ["sessions", "user_data", "models", "logs", "cache"]:
        (test_data_dir / subdir).mkdir(exist_ok=True)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    monkeypatch.setenv("DATA_DIR", str(test_data_dir))

@pytest.fixture
def mock_torch():
    """PyTorch ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    with patch('torch.cuda') as mock_cuda:
        mock_cuda.is_available.return_value = False
        mock_cuda.device_count.return_value = 0
        
        with patch('torch.device') as mock_device:
            mock_device.return_value = "cpu"
            yield mock_device

@pytest.fixture
def sample_text_data():
    """Ø¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    return {
        "arabic_texts": [
            "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ",
            "ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ",
            "Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ù„ÙˆØ¬ÙˆØ¯Ùƒ Ù‡Ù†Ø§",
            "Ù‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"
        ],
        "english_texts": [
            "Hello and welcome to the AI assistant",
            "How can I help you today?",
            "I'm happy to have you here",
            "This is a test text for testing"
        ],
        "mixed_content": [
            "Hello Ù…Ø±Ø­Ø¨Ø§Ù‹",
            "Thank you Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ",
            "AI Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
        ]
    }

@pytest.fixture
def performance_thresholds():
    """Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    return {
        "max_response_time": 5.0,  # Ø«ÙˆØ§Ù†ÙŠ
        "max_memory_usage": 500,   # Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
        "min_accuracy": 0.7,       # 70%
        "max_error_rate": 0.1      # 10%
    }

# Ù…Ø¹Ø§Ù„Ø¬Ø§Øª pytest
def pytest_collection_modifyitems(config, items):
    """ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¬Ù…Ø¹ Ù„Ù€ pytest"""
    for item in items:
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
        if asyncio.iscoroutinefunction(item.function):
            item.add_marker(pytest.mark.asyncio)

def pytest_runtest_setup(item):
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø¨Ù„ ØªØ´ØºÙŠÙ„ ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±"""
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚Ø¨Ù„ ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±
    import gc
    gc.collect()

def pytest_runtest_teardown(item):
    """ØªÙ†Ø¸ÙŠÙ Ø¨Ø¹Ø¯ ØªØ´ØºÙŠÙ„ ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±"""
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±
    import gc
    gc.collect()

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª pytest
pytest_plugins = ["pytest_asyncio"]
