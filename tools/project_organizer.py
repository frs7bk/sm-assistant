
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ุฃุฏุงุฉ ุชูุธูู ุงููุดุฑูุน ุงููุชูุฏูุฉ
ุชููู ุจุชูุธูู ูุฅุนุงุฏุฉ ููููุฉ ุงููุดุฑูุน ุจุทุฑููุฉ ุงุญุชุฑุงููุฉ
"""

import os
import shutil
import json
import logging
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass
import hashlib
import subprocess

@dataclass
class FileInfo:
    """ูุนูููุงุช ุงูููู"""
    path: Path
    size: int
    hash: str
    content_type: str
    is_duplicate: bool = False
    move_to: Optional[Path] = None

class ProjectOrganizer:
    """ููุธู ุงููุดุฑูุน ุงููุชูุฏู"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.logger = logging.getLogger(__name__)
        
        # ุงููููู ุงููุณุชูุฏู
        self.target_structure = {
            "core": ["ูุญุฑู ุงููุณุงุนุฏ ุงูุฃุณุงุณู", "*.py"],
            "ai_models": {
                "nlu": ["ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ", "*.py"],
                "nlg": ["ุชูููุฏ ุงููุบุฉ ุงูุทุจูุนูุฉ", "*.py"],
                "vision": ["ุงูุฑุคูุฉ ุงูุญุงุณูุจูุฉ", "*.py"],
                "learning": ["ุงูุชุนูู ุงูุขูู", "*.py"]
            },
            "analytics": {
                "big_data": ["ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุถุฎูุฉ", "*.py"],
                "prediction": ["ุฃูุธูุฉ ุงูุชูุจุค", "*.py"],
                "recommendation": ["ุฃูุธูุฉ ุงูุชูุตูุฉ", "*.py"],
                "visualization": ["ุงูุชุตูุฑ ูุงูุฑุณูู ุงูุจูุงููุฉ", "*.py"]
            },
            "interfaces": {
                "web": ["ูุงุฌูุงุช ุงูููุจ", "*.py", "*.html", "*.css", "*.js"],
                "voice": ["ูุงุฌูุงุช ุตูุชูุฉ", "*.py"],
                "api": ["ูุงุฌูุงุช ุจุฑูุฌูุฉ", "*.py"]
            },
            "config": ["ูููุงุช ุงูุชูููู", "*.py", "*.json", "*.yaml", "*.env"],
            "data": {
                "models": ["ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ", "*.pth", "*.pkl", "*.h5"],
                "cache": ["ูููุงุช ุงูุชุฎุฒูู ุงููุคูุช", "*"],
                "logs": ["ูููุงุช ุงูุณุฌูุงุช", "*.log"],
                "user_data": ["ุจูุงูุงุช ุงููุณุชุฎุฏููู", "*.json", "*.db"],
                "backups": ["ุงููุณุฎ ุงูุงุญุชูุงุทูุฉ", "*"]
            },
            "tests": ["ุงุฎุชุจุงุฑุงุช ุงูููุฏ", "test_*.py", "*_test.py"],
            "docs": ["ุงูุชูุซูู", "*.md", "*.rst", "*.txt"],
            "tools": ["ุฃุฏูุงุช ุงูุชุทููุฑ", "*.py"],
            "scripts": ["ุณูุฑูุจุชุงุช ุงูุชุดุบูู", "*.py", "*.sh", "*.bat"]
        }
        
        # ุงููููุงุช ุงูููุฑุฑุฉ
        self.duplicates: Dict[str, List[FileInfo]] = {}
        
        # ุฅุญุตุงุฆูุงุช
        self.stats = {
            "files_moved": 0,
            "files_deleted": 0,
            "duplicates_found": 0,
            "directories_created": 0,
            "total_space_saved": 0
        }
    
    def organize_project(self):
        """ุชูุธูู ุงููุดุฑูุน ุงููุงูู"""
        self.logger.info("๐๏ธ ุจุฏุก ุชูุธูู ุงููุดุฑูุน...")
        
        try:
            # ุงููุฑุญูุฉ 1: ุชุญููู ุงููููุงุช
            self._analyze_files()
            
            # ุงููุฑุญูุฉ 2: ุฅูุดุงุก ุงููููู ุงููุณุชูุฏู
            self._create_target_structure()
            
            # ุงููุฑุญูุฉ 3: ููู ุงููููุงุช
            self._move_files()
            
            # ุงููุฑุญูุฉ 4: ุญุฐู ุงูููุฑุฑุงุช
            self._remove_duplicates()
            
            # ุงููุฑุญูุฉ 5: ุชูุธูู ุงููุฌูุฏุงุช ุงููุงุฑุบุฉ
            self._cleanup_empty_directories()
            
            # ุงููุฑุญูุฉ 6: ุฅูุดุงุก ูููุงุช README
            self._create_readme_files()
            
            # ุงููุฑุญูุฉ 7: ุชุญุฏูุซ .gitignore
            self._update_gitignore()
            
            # ุงููุฑุญูุฉ 8: ุฅูุดุงุก ุชูุฑูุฑ
            self._generate_report()
            
            self.logger.info("โ ุชู ุชูุธูู ุงููุดุฑูุน ุจูุฌุงุญ")
            
        except Exception as e:
            self.logger.error(f"โ ุฎุทุฃ ูู ุชูุธูู ุงููุดุฑูุน: {e}")
    
    def _analyze_files(self):
        """ุชุญููู ุฌููุน ุงููููุงุช ูู ุงููุดุฑูุน"""
        self.logger.info("๐ ุชุญููู ุงููููุงุช...")
        
        file_hashes: Dict[str, List[FileInfo]] = {}
        
        for file_path in self.project_root.rglob("*"):
            if file_path.is_file() and not self._should_ignore_file(file_path):
                try:
                    file_info = self._get_file_info(file_path)
                    
                    if file_info.hash in file_hashes:
                        file_hashes[file_info.hash].append(file_info)
                    else:
                        file_hashes[file_info.hash] = [file_info]
                        
                except Exception as e:
                    self.logger.warning(f"ุฎุทุฃ ูู ุชุญููู {file_path}: {e}")
        
        # ุชุญุฏูุฏ ุงูููุฑุฑุงุช
        for file_hash, files in file_hashes.items():
            if len(files) > 1:
                self.duplicates[file_hash] = files
                for file_info in files:
                    file_info.is_duplicate = True
                
                self.stats["duplicates_found"] += len(files) - 1
        
        self.logger.info(f"๐ ุชู ุงูุนุซูุฑ ุนูู {self.stats['duplicates_found']} ููู ููุฑุฑ")
    
    def _get_file_info(self, file_path: Path) -> FileInfo:
        """ุงูุญุตูู ุนูู ูุนูููุงุช ุงูููู"""
        stat = file_path.stat()
        
        # ุญุณุงุจ hash
        with open(file_path, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        
        # ุชุญุฏูุฏ ููุน ุงููุญุชูู
        content_type = self._determine_content_type(file_path)
        
        return FileInfo(
            path=file_path,
            size=stat.st_size,
            hash=file_hash,
            content_type=content_type
        )
    
    def _determine_content_type(self, file_path: Path) -> str:
        """ุชุญุฏูุฏ ููุน ูุญุชูู ุงูููู"""
        suffix = file_path.suffix.lower()
        
        type_mapping = {
            '.py': 'python',
            '.js': 'javascript',
            '.html': 'html',
            '.css': 'css',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.md': 'markdown',
            '.txt': 'text',
            '.log': 'log',
            '.db': 'database',
            '.sqlite': 'database',
            '.pth': 'model',
            '.pkl': 'model',
            '.h5': 'model',
            '.jpg': 'image',
            '.png': 'image',
            '.gif': 'image',
            '.mp3': 'audio',
            '.wav': 'audio',
            '.mp4': 'video',
            '.avi': 'video'
        }
        
        return type_mapping.get(suffix, 'unknown')
    
    def _should_ignore_file(self, file_path: Path) -> bool:
        """ุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ูุฌุจ ุชุฌุงูู ุงูููู"""
        ignore_patterns = [
            '.git', '__pycache__', '.pytest_cache',
            'node_modules', '.vscode', '.idea',
            '*.pyc', '*.pyo', '*.egg-info',
            '.env', '.DS_Store', 'Thumbs.db'
        ]
        
        path_str = str(file_path)
        
        for pattern in ignore_patterns:
            if pattern in path_str:
                return True
        
        return False
    
    def _create_target_structure(self):
        """ุฅูุดุงุก ุงููููู ุงููุณุชูุฏู"""
        self.logger.info("๐๏ธ ุฅูุดุงุก ุงููููู ุงููุณุชูุฏู...")
        
        self._create_structure_recursive(self.target_structure, self.project_root)
    
    def _create_structure_recursive(self, structure: Dict, base_path: Path):
        """ุฅูุดุงุก ุงููููู ุจุทุฑููุฉ ุชูุฑุงุฑูุฉ"""
        for name, content in structure.items():
            dir_path = base_path / name
            
            if not dir_path.exists():
                dir_path.mkdir(parents=True, exist_ok=True)
                self.stats["directories_created"] += 1
                self.logger.info(f"๐ ุชู ุฅูุดุงุก ุงููุฌูุฏ: {dir_path}")
            
            if isinstance(content, dict):
                self._create_structure_recursive(content, dir_path)
    
    def _move_files(self):
        """ููู ุงููููุงุช ุฅูู ุงูููุงูุน ุงูุตุญูุญุฉ"""
        self.logger.info("๐ฆ ููู ุงููููุงุช...")
        
        # ููุงุนุฏ ุงูููู
        move_rules = {
            'assistant': ('core', 'ุงููููุงุช ุงูุฃุณุงุณูุฉ ูููุณุงุนุฏ'),
            'main': ('core', 'ูููุงุช ุงูุชุดุบูู ุงูุฑุฆูุณูุฉ'),
            'config': ('config', 'ูููุงุช ุงูุชูููู'),
            'settings': ('config', 'ูููุงุช ุงูุฅุนุฏุงุฏุงุช'),
            'bert_analyzer': ('ai_models/nlu', 'ูุญูู BERT'),
            'gpt4_interface': ('ai_models/nlu', 'ูุงุฌูุฉ GPT-4'),
            'gpt4_generator': ('ai_models/nlg', 'ูููุฏ GPT-4'),
            'fastspeech_tts': ('ai_models/nlg', 'ุชุญููู ุงููุต ุฅูู ููุงู'),
            'vision_pipeline': ('ai_models/vision', 'ุฎุท ูุนุงูุฌุฉ ุงูุฑุคูุฉ'),
            'active_learning': ('ai_models/learning', 'ุงูุชุนูู ุงููุดุท'),
            'few_shot_learner': ('ai_models/learning', 'ุงูุชุนูู ุจุงูุฃูุซูุฉ ุงูููููุฉ'),
            'reinforcement_engine': ('ai_models/learning', 'ูุญุฑู ุงูุชุนูู ุงููุนุฒุฒ'),
            'dask_processor': ('analytics/big_data', 'ูุนุงูุฌ Dask'),
            'spark_processor': ('analytics/big_data', 'ูุนุงูุฌ Spark'),
            'ml_predictor': ('analytics/prediction', 'ูุชูุจุฆ ุงูุชุนูู ุงูุขูู'),
            'dl_predictor': ('analytics/prediction', 'ูุชูุจุฆ ุงูุชุนูู ุงูุนููู'),
            'collaborative_filtering': ('analytics/recommendation', 'ุงูุชุตููุฉ ุงูุชุนุงูููุฉ'),
            'content_based': ('analytics/recommendation', 'ุงูุชูุตูุฉ ุงููุญุชูู'),
            'dash_dashboard': ('analytics/visualization', 'ููุญุฉ Dash'),
            'test_': ('tests', 'ูููุงุช ุงูุงุฎุชุจุงุฑ'),
            '_test': ('tests', 'ูููุงุช ุงูุงุฎุชุจุงุฑ'),
            'cleanup': ('tools', 'ุฃุฏูุงุช ุงูุชูุธูู'),
            'analyzer': ('tools', 'ุฃุฏูุงุช ุงูุชุญููู')
        }
        
        # ููู ุงููููุงุช ูู ุงููุฌูุฏ ุงูุฌุฐุฑ
        for file_path in self.project_root.glob("*.py"):
            if file_path.is_file():
                moved = False
                
                for pattern, (target_dir, description) in move_rules.items():
                    if pattern in file_path.stem.lower():
                        target_path = self.project_root / target_dir / file_path.name
                        
                        if not target_path.exists():
                            self._move_file_safely(file_path, target_path)
                            moved = True
                            break
                
                # ุฅุฐุง ูู ูุชู ููู ุงููููุ ุถุนู ูู ูุฌูุฏ misc
                if not moved and not self._is_important_root_file(file_path):
                    misc_dir = self.project_root / "misc"
                    misc_dir.mkdir(exist_ok=True)
                    target_path = misc_dir / file_path.name
                    
                    if not target_path.exists():
                        self._move_file_safely(file_path, target_path)
    
    def _is_important_root_file(self, file_path: Path) -> bool:
        """ุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ุงูููู ูููุงู ูู ุงููุฌูุฏ ุงูุฌุฐุฑ"""
        important_files = [
            'main_unified.py', 'setup.py', 'manage.py',
            'requirements.txt', 'pyproject.toml', 'README.md'
        ]
        
        return file_path.name in important_files
    
    def _move_file_safely(self, source: Path, target: Path):
        """ููู ุงูููู ุจุฃูุงู"""
        try:
            target.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(source), str(target))
            self.stats["files_moved"] += 1
            self.logger.info(f"๐ฆ ุชู ููู: {source.name} โ {target.parent.name}/")
            
        except Exception as e:
            self.logger.error(f"โ ุฎุทุฃ ูู ููู {source}: {e}")
    
    def _remove_duplicates(self):
        """ุญุฐู ุงููููุงุช ุงูููุฑุฑุฉ"""
        if not self.duplicates:
            return
        
        self.logger.info("๐๏ธ ุญุฐู ุงููููุงุช ุงูููุฑุฑุฉ...")
        
        for file_hash, files in self.duplicates.items():
            # ุงูุงุญุชูุงุธ ุจุฃูุถู ูุณุฎุฉ (ุงูุฃูุจุฑ ุฃู ูู ููุงู ุฃูุถู)
            best_file = self._choose_best_duplicate(files)
            
            for file_info in files:
                if file_info != best_file:
                    try:
                        file_info.path.unlink()
                        self.stats["files_deleted"] += 1
                        self.stats["total_space_saved"] += file_info.size
                        self.logger.info(f"๐๏ธ ุชู ุญุฐู ุงูููุฑุฑ: {file_info.path}")
                        
                    except Exception as e:
                        self.logger.error(f"โ ุฎุทุฃ ูู ุญุฐู {file_info.path}: {e}")
    
    def _choose_best_duplicate(self, files: List[FileInfo]) -> FileInfo:
        """ุงุฎุชูุงุฑ ุฃูุถู ูุณุฎุฉ ูู ุงููููุงุช ุงูููุฑุฑุฉ"""
        # ุงูุฃููููุฉ ูููููุงุช ูู ูุฌูุฏุงุช ููุธูุฉ
        organized_dirs = ['core', 'ai_models', 'analytics', 'interfaces']
        
        for directory in organized_dirs:
            for file_info in files:
                if directory in str(file_info.path):
                    return file_info
        
        # ุฅุฐุง ูู ุชูุฌุฏ ูู ูุฌูุฏุงุช ููุธูุฉุ ุงุฎุชุฑ ุงูุฃูุจุฑ
        return max(files, key=lambda f: f.size)
    
    def _cleanup_empty_directories(self):
        """ุชูุธูู ุงููุฌูุฏุงุช ุงููุงุฑุบุฉ"""
        self.logger.info("๐งน ุชูุธูู ุงููุฌูุฏุงุช ุงููุงุฑุบุฉ...")
        
        # ุงูุจุญุซ ุนู ุงููุฌูุฏุงุช ุงููุงุฑุบุฉ
        empty_dirs = []
        
        for dir_path in self.project_root.rglob("*"):
            if dir_path.is_dir() and not self._should_ignore_file(dir_path):
                try:
                    # ุชุญูู ูู ูุฌูุฏ ูููุงุช
                    if not any(dir_path.iterdir()):
                        empty_dirs.append(dir_path)
                except PermissionError:
                    continue
        
        # ุญุฐู ุงููุฌูุฏุงุช ุงููุงุฑุบุฉ
        for dir_path in empty_dirs:
            try:
                dir_path.rmdir()
                self.logger.info(f"๐๏ธ ุชู ุญุฐู ุงููุฌูุฏ ุงููุงุฑุบ: {dir_path}")
            except Exception as e:
                self.logger.warning(f"โ๏ธ ุชุนุฐุฑ ุญุฐู {dir_path}: {e}")
    
    def _create_readme_files(self):
        """ุฅูุดุงุก ูููุงุช README ูููุฌูุฏุงุช"""
        self.logger.info("๐ ุฅูุดุงุก ูููุงุช README...")
        
        readme_content = {
            "core": "# ุงููุญุฑู ุงูุฃุณุงุณู\nูุญุชูู ุนูู ุงููููุงุช ุงูุฃุณุงุณูุฉ ูุชุดุบูู ุงููุณุงุนุฏ ุงูุฐูู",
            "ai_models": "# ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู\nูุญุชูู ุนูู ุฌููุน ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุชุนูู ุงูุขูู",
            "ai_models/nlu": "# ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ\nููุงุฐุฌ ููู ูุชุญููู ุงููุบุฉ ุงูุทุจูุนูุฉ",
            "ai_models/nlg": "# ุชูููุฏ ุงููุบุฉ ุงูุทุจูุนูุฉ\nููุงุฐุฌ ุชูููุฏ ุงููุตูุต ูุงูุงุณุชุฌุงุจุงุช",
            "ai_models/vision": "# ุงูุฑุคูุฉ ุงูุญุงุณูุจูุฉ\nููุงุฐุฌ ูุนุงูุฌุฉ ูุชุญููู ุงูุตูุฑ",
            "ai_models/learning": "# ุงูุชุนูู ุงูุขูู\nุฎูุงุฑุฒููุงุช ุงูุชุนูู ูุงูุชููู",
            "analytics": "# ุงูุชุญูููุงุช ุงููุชูุฏูุฉ\nุฃุฏูุงุช ุชุญููู ุงูุจูุงูุงุช ูุงูุฅุญุตุงุฆูุงุช",
            "analytics/big_data": "# ุงูุจูุงูุงุช ุงูุถุฎูุฉ\nุฃุฏูุงุช ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุถุฎูุฉ",
            "analytics/prediction": "# ุฃูุธูุฉ ุงูุชูุจุค\nููุงุฐุฌ ุงูุชูุจุค ูุงูุชููุน",
            "analytics/recommendation": "# ุฃูุธูุฉ ุงูุชูุตูุฉ\nุฎูุงุฑุฒููุงุช ุงูุชูุตูุฉ ุงูุฐููุฉ",
            "analytics/visualization": "# ุงูุชุตูุฑ\nุฃุฏูุงุช ุฅูุดุงุก ุงูุฑุณูู ุงูุจูุงููุฉ ูุงูููุญุงุช",
            "config": "# ูููุงุช ุงูุชูููู\nุฌููุน ุฅุนุฏุงุฏุงุช ูุชููููุงุช ุงููุธุงู",
            "data": "# ุงูุจูุงูุงุช\nุชุฎุฒูู ุงูุจูุงูุงุช ูุงูููุงุฐุฌ ูุงููููุงุช",
            "tests": "# ุงูุงุฎุชุจุงุฑุงุช\nุงุฎุชุจุงุฑุงุช ุงููุญุฏุฉ ูุงูุชูุงูู",
            "tools": "# ุงูุฃุฏูุงุช\nุฃุฏูุงุช ุงูุชุทููุฑ ูุงูุตูุงูุฉ",
            "docs": "# ุงูุชูุซูู\nุฏููู ุงููุณุชุฎุฏู ูุงูุชูุซูู ุงูุชููู"
        }
        
        for dir_path, content in readme_content.items():
            readme_file = self.project_root / dir_path / "README.md"
            
            if not readme_file.exists():
                try:
                    readme_file.parent.mkdir(parents=True, exist_ok=True)
                    with open(readme_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    self.logger.info(f"๐ ุชู ุฅูุดุงุก README: {dir_path}")
                    
                except Exception as e:
                    self.logger.error(f"โ ุฎุทุฃ ูู ุฅูุดุงุก README ูู {dir_path}: {e}")
    
    def _update_gitignore(self):
        """ุชุญุฏูุซ ููู .gitignore"""
        gitignore_path = self.project_root / ".gitignore"
        
        gitignore_content = """
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
data/cache/
data/logs/
*.log
.env
temp/
misc/

# Models and large files
*.pth
*.h5
*.pkl
data/models/*.bin

# Temporary files
*.tmp
*.temp
"""
        
        try:
            with open(gitignore_path, 'w', encoding='utf-8') as f:
                f.write(gitignore_content.strip())
            
            self.logger.info("๐ ุชู ุชุญุฏูุซ .gitignore")
            
        except Exception as e:
            self.logger.error(f"โ ุฎุทุฃ ูู ุชุญุฏูุซ .gitignore: {e}")
    
    def _generate_report(self):
        """ุฅูุดุงุก ุชูุฑูุฑ ุงูุชูุธูู"""
        report = {
            "ุชุงุฑูุฎ_ุงูุชูุธูู": str(Path.cwd()),
            "ุฅุญุตุงุฆูุงุช": self.stats,
            "ุงููููุงุช_ุงูููุฑุฑุฉ_ุงููุญุฐููุฉ": len(self.duplicates),
            "ุงููุณุงุญุฉ_ุงููุญุฑุฑุฉ_ุจุงูุจุงูุช": self.stats["total_space_saved"],
            "ุงููุณุงุญุฉ_ุงููุญุฑุฑุฉ_MB": round(self.stats["total_space_saved"] / (1024 * 1024), 2)
        }
        
        report_path = self.project_root / "organization_report.json"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            self.logger.info("๐ ุชู ุฅูุดุงุก ุชูุฑูุฑ ุงูุชูุธูู")
            
            # ุทุจุงุนุฉ ุงูููุฎุต
            print("\n" + "="*50)
            print("๐ ููุฎุต ุชูุธูู ุงููุดุฑูุน")
            print("="*50)
            print(f"๐ฆ ุงููููุงุช ุงููููููุฉ: {self.stats['files_moved']}")
            print(f"๐๏ธ ุงููููุงุช ุงููุญุฐููุฉ: {self.stats['files_deleted']}")
            print(f"๐ ุงููุฌูุฏุงุช ุงูููุดุฃุฉ: {self.stats['directories_created']}")
            print(f"๐พ ุงููุณุงุญุฉ ุงููุญุฑุฑุฉ: {report['ุงููุณุงุญุฉ_ุงููุญุฑุฑุฉ_MB']} MB")
            print("="*50)
            
        except Exception as e:
            self.logger.error(f"โ ุฎุทุฃ ูู ุฅูุดุงุก ุงูุชูุฑูุฑ: {e}")

def main():
    """ุชุดุบูู ููุธู ุงููุดุฑูุน"""
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    organizer = ProjectOrganizer()
    organizer.organize_project()

if __name__ == "__main__":
    main()
